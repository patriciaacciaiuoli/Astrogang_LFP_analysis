{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_paths = {\"KO\": {\"C0\": [r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C0\\119C0_2024-10-11_12-54-00\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C0\\119C0_2024-10-11_12-54-00\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C0\\119C0_2024-10-11_12-54-00\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C0\\119C0_2024-10-11_12-54-00\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C0\\119C0_2024-10-11_12-54-00\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C0\\119C0_2024-10-11_12-54-00\\Record Node 107\\experiment1\\recording6\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C0\\119C0_2024-10-11_12-54-00\\Record Node 107\\experiment1\\recording7\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "#         ],\n",
    "#         \"C1\": [\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C1\\119C1_2024-10-14_13-12-51\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\", \n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C1\\119C1_2024-10-14_13-12-51\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C1\\119C1_2024-10-14_13-12-51\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C1\\119C1_2024-10-14_13-12-51\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C1\\119C1_2024-10-14_13-12-51\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C1\\119C1_2024-10-14_13-12-51\\Record Node 107\\experiment1\\recording6\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C1\\119C1_2024-10-14_13-12-51\\Record Node 107\\experiment1\\recording7\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "\n",
    "#         ],\n",
    "#         \"C2\":[r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C2\\119C2_2024-10-15_13-09-04\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C2\\119C2_2024-10-15_13-09-04\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C2\\119C2_2024-10-15_13-09-04\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C2\\119C2_2024-10-15_13-09-04\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C2\\119C2_2024-10-15_13-09-04\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "#         ],\n",
    "#         \"C4\":[r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C4\\119C4_2024-10-24_12-29-02\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C4\\119C4_2024-10-24_12-29-02\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C4\\119C4_2024-10-24_12-29-02\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C4\\119C4_2024-10-24_12-29-02\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C4\\119C4_2024-10-24_12-29-02\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "#             r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C4\\119C4_2024-10-24_12-29-02\\Record Node 107\\experiment1\\recording6\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "#         ]\n",
    "#     }\n",
    "        \n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "import ajlab2 as aj\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy.signal import welch\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "data_paths = {\"KO\": {\"C0\": [r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C0\\119C0_2024-10-11_12-54-00\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C0\\119C0_2024-10-11_12-54-00\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C0\\119C0_2024-10-11_12-54-00\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C0\\119C0_2024-10-11_12-54-00\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C0\\119C0_2024-10-11_12-54-00\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C0\\119C0_2024-10-11_12-54-00\\Record Node 107\\experiment1\\recording6\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C0\\119C0_2024-10-11_12-54-00\\Record Node 107\\experiment1\\recording7\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"C1\": [\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C1\\119C1_2024-10-14_13-12-51\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\", \n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C1\\119C1_2024-10-14_13-12-51\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C1\\119C1_2024-10-14_13-12-51\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C1\\119C1_2024-10-14_13-12-51\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C1\\119C1_2024-10-14_13-12-51\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C1\\119C1_2024-10-14_13-12-51\\Record Node 107\\experiment1\\recording6\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C1\\119C1_2024-10-14_13-12-51\\Record Node 107\\experiment1\\recording7\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "\n",
    "        ],\n",
    "        \"C2\":[r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C2\\119C2_2024-10-15_13-09-04\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C2\\119C2_2024-10-15_13-09-04\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C2\\119C2_2024-10-15_13-09-04\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C2\\119C2_2024-10-15_13-09-04\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C2\\119C2_2024-10-15_13-09-04\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"C4\":[r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C4\\119C4_2024-10-24_12-29-02\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C4\\119C4_2024-10-24_12-29-02\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C4\\119C4_2024-10-24_12-29-02\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C4\\119C4_2024-10-24_12-29-02\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C4\\119C4_2024-10-24_12-29-02\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\C4\\119C4_2024-10-24_12-29-02\\Record Node 107\\experiment1\\recording6\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"B0\":[\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\B0\\119B0_2024-08-07_13-06-21\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\B0\\119B0_2024-08-07_13-06-21\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"B1\":[\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\B1\\119B1_2024-08-09_13-33-01\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\KO\\B1\\119B1_2024-08-09_13-33-01\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"B8\":[\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\KO\\B8\\115B8_2024-11-12_12-54-41\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\KO\\B8\\115B8_2024-11-12_12-54-41\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\KO\\B8\\115B8_2024-11-12_12-54-41\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\KO\\B8\\115B8_2024-11-12_12-54-41\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\KO\\B8\\115B8_2024-11-12_12-54-41\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ]\n",
    "    },\n",
    "    \"WT\": {\n",
    "        \"D0\": [\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D0\\119D0_2024-10-16_13-29-54\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D0\\119D0_2024-10-16_13-29-54\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D0\\119D0_2024-10-16_13-29-54\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D0\\119D0_2024-10-16_13-29-54\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D0\\119D0_2024-10-16_13-29-54\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D0\\119D0_2024-10-16_13-29-54\\Record Node 107\\experiment1\\recording6\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"D1\": [\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D1\\119D1_2024-10-17_12-30-05\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D1\\119D1_2024-10-17_12-30-05\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D1\\119D1_2024-10-17_12-30-05\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D1\\119D1_2024-10-17_12-30-05\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D1\\119D1_2024-10-17_12-30-05\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "            \n",
    "        ],\n",
    "        \"D2\":[\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D2\\119D2_2024-10-18_12-40-29\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D2\\119D2_2024-10-18_12-40-29\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D2\\119D2_2024-10-18_12-40-29\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D2\\119D2_2024-10-18_12-40-29\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D2\\119D2_2024-10-18_12-40-29\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D2\\119D2_2024-10-18_12-40-29\\Record Node 107\\experiment1\\recording6\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"D3\":[\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D3\\119D3_2024-10-22_12-50-11\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D3\\119D3_2024-10-22_12-50-11\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D3\\119D3_2024-10-22_12-50-11\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D3\\119D3_2024-10-22_12-50-11\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D3\\119D3_2024-10-22_12-50-11\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"D4\":[\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D4\\119D4_2024-10-25_12-38-18\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D4\\119D4_2024-10-25_12-38-18\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D4\\119D4_2024-10-25_12-38-18\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\D4\\119D4_2024-10-25_12-38-18\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"D0-B\":[\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\WT\\D0\\120D0_2024-11-27_12-30-37\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\WT\\D0\\120D0_2024-11-27_12-30-37\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"D1-B\":[\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\WT\\D1\\120D1_2024-11-28_12-56-08\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\WT\\D1\\120D1_2024-11-28_12-56-08\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"D2-B\":[\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\WT\\D2\\120D2_2024-11-29_12-10-35\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\WT\\D2\\120D2_2024-11-29_12-10-35\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"D7-B\":[\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\WT\\D7\\120D7_2024-12-02_12-33-52\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\WT\\D7\\120D7_2024-12-02_12-33-52\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"D9-B\":[\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\WT\\D9\\120D9_2024-12-04_12-12-28\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\WT\\D9\\120D9_2024-12-04_12-12-28\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"A0-B\":[\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\WT\\A0\\120A0_2024-11-18_12-33-39\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\WT\\A0\\120A0_2024-11-18_12-33-39\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"A3-B\":[\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\WT\\A3\\120A3_2024-11-19_12-52-13\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\WT\\A3\\120A3_2024-11-19_12-52-13\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"B8-B\":[\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\KO\\B8\\120B8_2024-12-05_12-06-50\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\KO\\B8\\120B8_2024-12-05_12-06-50\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"C0-B\":[\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\KO\\C0\\120C0_2024-11-20_12-55-48\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\KO\\C0\\120C0_2024-11-20_12-55-48\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"C1-B\":[\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\KO\\C1\\120C1_2024-11-21_12-21-31\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\KO\\C1\\120C1_2024-11-21_12-21-31\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"C2-B\":[\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\KO\\C2\\120C2_2024-11-22_12-00-03\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\KO\\C2\\120C2_2024-11-22_12-00-03\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"C3-B\":[\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\KO\\C3\\120C3_2024-11-25_12-20-47\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\KO\\C3\\120C3_2024-11-25_12-20-47\\Record Node 107\\experiment1\\recording5\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"C5-B\":[\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\KO\\C5\\120C5_2024-11-26_12-40-56\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"C:\\Astrogang Ephys_Bruna\\Recordings\\Set120 - ALDH1L1\\KO\\C5\\120C5_2024-11-26_12-40-56\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"A0\":[\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\A0\\119A0_2024-08-05_11-58-30\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\A0\\119A0_2024-08-05_11-58-30\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"A1\":[\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\A1\\119A1_2024-08-06_13-34-13\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 119 - IP3R2KO\\WT\\A1\\119A1_2024-08-06_13-34-13\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"A2\":[\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\A2\\115A2_2024-10-29_13-21-25\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\A2\\115A2_2024-10-29_13-21-25\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\A2\\115A2_2024-10-29_13-21-25\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\A2\\115A2_2024-10-29_13-21-25\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\A2\\115A2_2024-10-29_13-21-25\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"C0\":[\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\C0\\115C0_2024-10-30_12-52-45\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\C0\\115C0_2024-10-30_12-52-45\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\C0\\115C0_2024-10-30_12-52-45\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\C0\\115C0_2024-10-30_12-52-45\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\C0\\115C0_2024-10-30_12-52-45\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\C0\\115C0_2024-10-30_12-52-45\\Record Node 107\\experiment1\\recording6\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\C0\\115C0_2024-10-30_12-52-45\\Record Node 107\\experiment1\\recording7\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ],\n",
    "        \"B1\":[\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\B1\\115B1_2024-11-11_12-27-01\\Record Node 107\\experiment1\\recording1\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\B1\\115B1_2024-11-11_12-27-01\\Record Node 107\\experiment1\\recording2\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\B1\\115B1_2024-11-11_12-27-01\\Record Node 107\\experiment1\\recording3\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\B1\\115B1_2024-11-11_12-27-01\\Record Node 107\\experiment1\\recording4\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\",\n",
    "            r\"D:\\Astrogang Ephys_Patricia\\Recordings\\Set 115 - FOXO1-\\WT\\B1\\115B1_2024-11-11_12-27-01\\Record Node 107\\experiment1\\recording5\\continuous\\Acquisition_Board-106.Rhythm Data\\continuous.dat\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "num_channels=64\n",
    "sample_rate=30000\n",
    "\n",
    "def load_data(group, subset, recording_idx, duration, start_time):\n",
    "    \n",
    "    dat_filename = data_paths[group][subset][recording_idx - 1]\n",
    "\n",
    "    \n",
    "    statinfo = os.stat(dat_filename)\n",
    "    filesize = statinfo.st_size\n",
    "    pop_sample_size_in_bytes = num_channels * 2  # 2 bytes por amostra (int16)\n",
    "    num_samples = int(filesize / pop_sample_size_in_bytes)\n",
    "\n",
    "    \n",
    "    total_duration = num_samples / sample_rate\n",
    "    print(f\"Duração total da gravação: {total_duration:.2f} segundos\")\n",
    "\n",
    "    \n",
    "    if duration is not None:\n",
    "        if start_time + duration > total_duration:\n",
    "            print(\"A duração especificada excede a duração total da gravação. Ajustando a duração.\")\n",
    "            duration = total_duration - start_time\n",
    "\n",
    "    \n",
    "    start_sample = int(start_time * sample_rate)\n",
    "    if duration is not None:\n",
    "        end_sample = start_sample + int(duration * sample_rate)\n",
    "    else:\n",
    "        end_sample = num_samples  \n",
    "\n",
    "    # Garantir que os índices não ultrapassem o tamanho do arquivo\n",
    "    end_sample = min(end_sample, num_samples)\n",
    "\n",
    "    \n",
    "    mem_map_data = np.memmap(dat_filename, dtype='int16', mode='r', shape=(num_samples, num_channels))\n",
    "    print('start',start_sample)\n",
    "    print('end',end_sample)\n",
    "    \n",
    "    return mem_map_data[-5*60*sample_rate:,:], dat_filename\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duração total da gravação: 900.17 segundos\n",
      "start 18003300\n",
      "end 27003300\n",
      "(9000000, 64)\n"
     ]
    }
   ],
   "source": [
    "genotype = 'WT'\n",
    "animal = 'A1'\n",
    "number_recording = 2\n",
    "duration_to_load = 300  # 5 minutos \n",
    "\n",
    "\n",
    "statinfo = os.stat(data_paths[genotype][animal][1-1])  \n",
    "filesize = statinfo.st_size\n",
    "pop_sample_size_in_bytes = num_channels * 2 \n",
    "num_samples = int(filesize / pop_sample_size_in_bytes)\n",
    "total_duration = num_samples / sample_rate  \n",
    "\n",
    "# Calcular o ponto de início para os últimos 5 minutos\n",
    "starttime = total_duration - duration_to_load\n",
    "\n",
    "anesthesia = {'KO': {'C0': ['4', '3.5', '3', '2.5', '2', '1.5','1'],'C1': ['4', '3.5', '3', '2.5', '2', '1.5','1'],'C2': ['4', '3.5', '3', '2.5', '2'],'C4': ['4', '3.5', '3', '2.5', '2', '1.5'],'B0':['4','2.5'],'B1':['4','2.5'],'B8':['4', '3.5', '3', '2.5', '2']},\n",
    "    'WT': {'D0': ['4', '3.5', '3', '2.5', '2', '1.5'],  'D1': ['4', '3.5', '3', '2.5', '2'],'D2': ['4', '3.5', '3', '2.5', '2', '1.5'],'D3': ['4', '3.5', '3', '2.5', '2'],'D4': ['4', '3.5', '3', '2.5'],'D0-B':['4','2'],'D1-B':['4','2'],'D2-B':['4','2'],'D7-B':['4','2'],'D9-B':['4','2'],'A0-B':['4','2'],'A3-B':['4','2'],'B8-B':['4','2'],'C0-B':['4','2'],'C1-B':['4','2'],'C2-B':['4','2'],'C3-B':['4','2'],'C5-B':['4','2'],'A0':['4','2.5'],'A1':['4','2.5'],'A2':['4', '3.5', '3', '2.5', '2'],'C0':['4', '3.5', '3', '2.5', '2', '1.5','1'],'B1':['4', '3.5', '3', '2.5', '2']}}\n",
    "\n",
    "mem_map_data, dat_filename = load_data(genotype, animal, number_recording,duration_to_load,starttime)\n",
    "\n",
    "\n",
    "\n",
    "print(mem_map_data.shape)\n",
    "\n",
    "anesthesia_level = anesthesia[genotype][animal][number_recording-1] if number_recording-1 >= 0 else \"Desconhecido\"\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(13, 5))\n",
    "# plt.plot(mem_map_data[:, 0])  \n",
    "# plt.title(f\"{genotype} - {animal} - Anesthesia {anesthesia_level}\")\n",
    "# plt.xlabel(\"Samples)\")\n",
    "# plt.ylabel(\"Amplitude\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19 18 24 17 23 16 21 31 20 30 25  7 22 12 29 11 28 10 27  8 26  2  3 14\n",
      "  6 13  9  1  5  0  4 15 51 50 56 49 55 48 53 63 52 62 57 39 54 44 61 43\n",
      " 60 42 59 40 58 34 35 46 38 45 41 33 37 32 36 47]\n"
     ]
    }
   ],
   "source": [
    "ti=22\n",
    "tf=23\n",
    "time = np.arange(ti, tf, 1/sample_rate)\n",
    "#map=np.concatenate((np.array([20,19,25,18,24,17,22,32,21,31,26,8,23,13,30,12,29,11,28,9,27,3,4,15,7,14,10,2,6,1,5,16]),np.array([20,19,25,18,24,17,22,32,21,31,26,8,23,13,30,12,29,11,28,9,27,3,4,15,7,14,10,2,6,1,5,16])+32))\n",
    "map=np.concatenate((np.array([20,19,25,18,24,17,22,32,21,31,26,8,23,13,30,12,29,11,28,9,27,3,4,15,7,14,10,2,6,1,5,16]),np.array([20,19,25,18,24,17,22,32,21,31,26,8,23,13,30,12,29,11,28,9,27,3,4,15,7,14,10,2,6,1,5,16])+32))\n",
    "# map=np.concatenate((np.array([20,19,25,18,24,17,22,32,21,31,26,8,23,13,30,12,29,11,28,9,27,3,4,15,7,14,10,2,6,1,5,16]),np.array([20,19,25,18,24,17,22,32,21,31,26,8,23,13,30,12,29,11,28,9,27,3,4,7,14,10,2,6,1,5])+32))\n",
    "\n",
    "map-=1\n",
    "print(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# duration=mem_map_data.shape[0]/(sample_rate)\n",
    "# #time = np.arange(1/sample_rate,duration,1/sample_rate)\n",
    "\n",
    "# fig=plt.figure(figsize=(20,10))\n",
    "# count=0\n",
    "\n",
    "# for i in map[0:10]:\n",
    "\n",
    "#     plt.plot(time,(mem_map_data[ti*sample_rate:tf*sample_rate,i]*.195)+count, label=f' shank 1channel {i}',color='olivedrab') #.195 is a factor that multiplies the digital signals to convert them to microvolts, so that the data is saved as integers.\n",
    "#     count+=70 #just so that the data does not overlap.\n",
    "# for i in map[10:21]:\n",
    "#     plt.plot(time,(mem_map_data[ti*sample_rate:tf*sample_rate,i]*.195)+count, label=f'shank 2channel {i}',color='red') #.195 is a factor that multiplies the digital signals to convert them to microvolts, so that the data is saved as integers.\n",
    "#     count+=70 #just so that the data does not overlap.\n",
    "# for i in map[21:32]:\n",
    "#     plt.plot(time,(mem_map_data[ti*sample_rate:tf*sample_rate,i]*.195)+count, label=f'shank 3 channel {i}',color='blue') #.195 is a factor that multiplies the digital signals to convert them to microvolts, so that the data is saved as integers.\n",
    "#     count+=70 #just so that the data does not overlap.\n",
    "# plt.xlabel(\"time (s)\")\n",
    "# plt.title('HIP')\n",
    "# plt.legend(loc='upper right', bbox_to_anchor=(1.15,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig=plt.figure(figsize=(20,10))\n",
    "\n",
    "# #for i in map[32:42]:\n",
    "# #    plt.plot(time,(mem_map_data[ti*sample_rate:tf*sample_rate,i]*.195)+count, label=f' shank 1channel {i}',color='olivedrab') #.195 is a factor that multiplies the digital signals to convert them to microvolts, so that the data is saved as integers.\n",
    "# #    count+=100 #just so that the data does not overlap.\n",
    "# for i in map[32:43]:\n",
    "#     plt.plot(time,(mem_map_data[ti*sample_rate:tf*sample_rate,i]*.195)+count, label=f'shank 2channel {i}',color='red') #.195 is a factor that multiplies the digital signals to convert them to microvolts, so that the data is saved as integers.\n",
    "#     count+=100 #just so that the data does not overlap.\n",
    "# #for i in map[53:64]:\n",
    "# #    plt.plot(time,(mem_map_data[ti*sample_rate:tf*sample_rate,i]*.195)+count, label=f'shank 3 channel {i}',color='blue') #.195 is a factor that multiplies the digital signals to convert them to microvolts, so that the data is saved as integers.\n",
    "# #    count+=100 #just so that the data does not overlap.\n",
    "# plt.xlabel(\"time (s)\")\n",
    "# plt.title('PFC')\n",
    "# plt.legend(loc='upper right', bbox_to_anchor=(1.15,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(13, 3))\n",
    "\n",
    "# plt.plot(time,mem_map_data[ti*sample_rate:tf*sample_rate,30]*.195, \"k\")\n",
    "# plt.xlabel(\"Time (s)\")\n",
    "# plt.ylabel(\"voltage (μV)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, sosfilt\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    sos = butter(order, [low, high], analog=False, btype='band', output='sos')\n",
    "    return sos\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    # data = data\n",
    "    # lowcut = low frenquency\n",
    "    # highcut = hight frequency to cut\n",
    "    # fs = sample rate\n",
    "    # order= order\n",
    "    sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = sosfilt(sos, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs  # Frequência de Nyquist\n",
    "    normal_cutoff = cutoff / nyq  # Normalizando a frequência de corte\n",
    "    sos = butter(order, normal_cutoff, analog=False, btype='low', output='sos')  # Filtro passa-baixa\n",
    "    return sos\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    sos = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = sosfilt(sos, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def butter_bandstop(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs  # Frequência de Nyquist\n",
    "    normal_cutoff = np.array(cutoff) / nyq  # Normalizando as frequências de corte\n",
    "    sos = butter(order, normal_cutoff, btype='bandstop', analog=False, output='sos')  # Filtro rejeita-banda\n",
    "    return sos\n",
    "\n",
    "def butter_bandstop_filter(data, cutoff, fs, order=5):\n",
    "    sos = butter_bandstop(cutoff, fs, order=order)\n",
    "    y = sosfilt(sos, data)\n",
    "    return y\n",
    "#data_filter = butter_bandpass_filter(data=all_data[:,:]*.195, lowcut=300, highcut=3000, fs=sample_rate, order=4)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000000, 64)\n"
     ]
    }
   ],
   "source": [
    "# # ## ORIGINAL\n",
    "# \n",
    "data_filter=[]\n",
    "\n",
    "\n",
    "for i in map[:]:  # 64 canais\n",
    "    # print(f\"Processando canal {i}\")\n",
    "    sinalfiltrado = butter_bandpass_filter(data=mem_map_data[:, i] * 0.195, lowcut=0.1,highcut=300, fs=sample_rate, order=5)\n",
    "    sinalfiltrado=butter_bandstop_filter(sinalfiltrado,cutoff=[49,51],fs=sample_rate,order=5)\n",
    "    data_filter.append(sinalfiltrado)  \n",
    "data_filter = np.array(data_filter).T\n",
    "len(data_filter)\n",
    "print(data_filter.shape)\n",
    "\n",
    "NPS =1200 # length of the segment\n",
    "NVL = NPS//2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 119 - IP3R2KO\n",
      "600.0\n"
     ]
    }
   ],
   "source": [
    "dat_path = data_paths[genotype][animal][number_recording - 1]\n",
    "set_folder = os.path.normpath(dat_path).split(os.sep)[3]\n",
    "\n",
    "print(set_folder)\n",
    "\n",
    "base_dir = os.path.join(r\"D:\\Astrogang Ephys_Patricia\\PLOTS\", set_folder)\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "sub_sampling=50   \n",
    "SFs=sample_rate/sub_sampling \n",
    "print(SFs)\n",
    "\n",
    "data_filter=data_filter[::sub_sampling,:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 119 - IP3R2KO\n"
     ]
    }
   ],
   "source": [
    "dat_path = data_paths[genotype][animal][number_recording - 1]\n",
    "set_folder = os.path.normpath(dat_path).split(os.sep)[3]\n",
    "\n",
    "print(set_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180000, 64)\n"
     ]
    }
   ],
   "source": [
    "NPS =1200 # length of the segment\n",
    "NVL = NPS//2 \n",
    "len(data_filter)\n",
    "print(data_filter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # PARA REMOVER CANAIS\n",
    "# data_filter=[]\n",
    "\n",
    "# # idx_ch_47=np.where(map==47)[0]\n",
    "# # idx_ch_48=np.where(map==48)[0]\n",
    "\n",
    "# for i in map[:]:  # 64 canais\n",
    "#     # print(f\"Processando canal {i}\")\n",
    "#     if i==47 or i==48:\n",
    "#         print(f' canal {i} removido')\n",
    "#     else:\n",
    "#         sinalfiltrado = butter_bandpass_filter(data=mem_map_data[:, i] * 0.195, lowcut=0.1,highcut=300, fs=sample_rate, order=5)\n",
    "#         sinalfiltrado=butter_bandstop_filter(sinalfiltrado,cutoff=[49,51],fs=sample_rate,order=5)\n",
    "#         data_filter.append(sinalfiltrado)  \n",
    "# data_filter = np.array(data_filter).T\n",
    "# # len(data_filter)\n",
    "# print(data_filter.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hip_shank1\n",
      "max [3633.4432480278583, 3798.7537724540803, 2185.1453911895233, 3063.0845187467753, 1482.4080386741828, 2160.0414846304625, 1201.0665653554015, 994.9261938276082, 680.3713601877447, 516.5025204118612]\n",
      "media 1971.5743093505498\n",
      "media+desvio 4247.02296950267\n",
      "hip_shank2\n",
      "max [3969.8789445231328, 3489.6879889962897, 4036.5951408090677, 4602.720757756671, 4398.219955523809, 4333.063685481794, 4140.067821741215, 4078.4494206134764, 3535.262459525233, 2783.433136473742, 2172.511803602503]\n",
      "media 3776.3537377315397\n",
      "media+desvio 5178.52813572929\n",
      "hip_shank3\n",
      "max [3297.4577791576567, 3814.1783540147935, 3576.7451437775203, 3842.635681670353, 4186.449729109786, 4150.364489924694, 4128.78710232066, 4103.510438277535, 3616.590540182072, 3049.443759756264, 2748.8370716189806]\n",
      "media 3683.1818263463924\n",
      "media+desvio 4603.366454939799\n",
      "pfc_shank1\n",
      "max [1125.1500043314843, 2779.517162618451, 960.0790420340903, 3258.3373014676863, 757.8157533352859, 5547.360318569616, 647.1451637368742, 4059.717542826459, 596.2812686479036, 3507.9347856793224]\n",
      "media 2323.9338343247173\n",
      "media+desvio 5636.471211374455\n",
      "pfc_shank2\n",
      "max [288.37463606179307, 290.32700852046463, 290.8805738866935, 289.5084341800972, 307.34090429148046, 271.0901237776212, 262.3531325817433, 271.59375513791036, 297.71246828709894, 247.89448905663303, 276.3459414948463]\n",
      "media 281.220133388762\n",
      "media+desvio 313.8950511860202\n",
      "pfc_shank3\n",
      "max [2451.3693121742376, 1186.1717272072776, 3580.2204855805066, 1057.194235751389, 1914.279337770086, 722.3476809017955, 3190.049448722309, 664.4052175450145, 3861.9256600449976, 525.200739704331, 5658.424992827224]\n",
      "media 2255.5989852935604\n",
      "media+desvio 5412.066458173214\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "[19, 18, 24, 17, 23, 16, 21, 31, 20, 30, 25, 7, 22, 12, 29, 11, 28, 10, 27, 8, 26, 2, 3, 14, 6, 13, 9, 1, 5, 0, 4, 15, 51, 50, 56, 49, 55, 48, 53, 63, 52, 62, 57, 39, 54, 44, 61, 43, 60, 42, 59, 40, 58, 34, 35, 46, 38, 45, 41, 33, 37, 32, 36]\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import welch\n",
    "\n",
    "index_map = {\n",
    "    'hip_shank1': list(range(0, 10)),  \n",
    "    'hip_shank2': list(range(10, 21)),  \n",
    "    'hip_shank3': list(range(21, 32)),\n",
    "    'pfc_shank1': list(range(32, 42)),  \n",
    "    'pfc_shank2': list(range(42, 53)),\n",
    "    'pfc_shank3': list(range(53, 64))\n",
    "}\n",
    "\n",
    "\n",
    "filtered_shanks = {}\n",
    "channel_mapping={}\n",
    "\n",
    "a=[]\n",
    "map_removido=[]\n",
    "for shank_name, channels in index_map.items():\n",
    "    all_Pxx_max = []  \n",
    "    \n",
    "    for ch in channels:\n",
    "        sinal = data_filter[:, ch]  \n",
    "        f, Pxx = signal.welch(sinal, SFs, nperseg=NPS, noverlap=NVL)\n",
    "        all_Pxx_max.append(max(Pxx))\n",
    "\n",
    "    print(shank_name)\n",
    "    print('max',all_Pxx_max)\n",
    "    media = np.mean(all_Pxx_max)\n",
    "    desvio = np.std(all_Pxx_max)\n",
    "    limite = media + 2 * desvio\n",
    "    print('media',media)\n",
    "    # print('desvio',desvio)\n",
    "    print('media+desvio',limite)\n",
    "    valid_channels = []\n",
    "\n",
    "    for i, ch in enumerate(channels):\n",
    "        if all_Pxx_max[i] <= limite:  \n",
    "            valid_channels.append(map[ch])\n",
    "            map_removido.append(map[ch])\n",
    "            a.append(1)\n",
    "        else:\n",
    "            a.append(0)\n",
    "    \n",
    "\n",
    "    filtered_shanks[shank_name] = valid_channels\n",
    "    channel_mapping[shank_name] = {i: ch for i, ch in enumerate(valid_channels)}\n",
    "\n",
    "print(a)\n",
    "print(map_removido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 18, 24, 17, 23, 16, 21, 31, 20, 30, 25, 7, 22, 12, 29, 11, 28, 10, 27, 8, 26, 2, 3, 14, 6, 13, 9, 1, 5, 0, 4, 15, 51, 50, 56, 49, 55, 48, 53, 63, 52, 62, 57, 39, 54, 44, 61, 43, 60, 42, 59, 40, 58, 34, 35, 46, 38, 45, 41, 33, 37, 32, 36]\n",
      "[19, 18, 24, 17, 23, 16, 21, 31, 20, 30, 25, 7, 22, 12, 29, 11, 28, 10, 27, 8, 26, 2, 3, 14, 6, 13, 9, 1, 5, 0, 4, 15, 51, 50, 56, 49, 55, 48, 53, 63, 52, 62, 57, 39, 54, 44, 61, 43, 60, 42, 59, 40, 58, 34, 35, 46, 38, 45, 41, 33, 37, 32, 36]\n",
      "[47]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "map_removido_a = [map[i] for i in range(len(a)) if a[i] == 1]\n",
    "canais_removidos=[i for i in map if i not in map_removido]\n",
    "idx_validos=[i for i,ch in enumerate(map)if ch in map_removido]\n",
    "idx_total=list(range(0,64))\n",
    "data_filter = data_filter[:,idx_validos]\n",
    "# data_filter=data_filter[:,[i for i in map_removido]]\n",
    "\n",
    "print(map_removido)\n",
    "print(map_removido_a)\n",
    "# print(len(data_filter))\n",
    "print(canais_removidos)\n",
    "print(idx_validos)\n",
    "print(idx_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180000, 63)\n",
      "[19, 18, 24, 17, 23, 16, 21, 31, 20, 30, 25, 7, 22, 12, 29, 11, 28, 10, 27, 8, 26, 2, 3, 14, 6, 13, 9, 1, 5, 0, 4, 15, 51, 50, 56, 49, 55, 48, 53, 63, 52, 62, 57, 39, 54, 44, 61, 43, 60, 42, 59, 40, 58, 34, 35, 46, 38, 45, 41, 33, 37, 32, 36]\n",
      "[63]\n"
     ]
    }
   ],
   "source": [
    "print(data_filter.shape)\n",
    "print(map_removido)\n",
    "idx_removidos = [i for i in idx_total if i not in idx_validos]\n",
    "print(idx_removidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "removed_channels_str = \", \".join([str(ch) for ch in canais_removidos])\n",
    "\n",
    "output_path = r\"C:\\Users\\Medicina\\MEOCloud\\Astrogang_Ephys\\ag_PatriciaAzenha\\Análise dados\\Canais removidos_t\"\n",
    "output_path=os.path.join(output_path, set_folder)\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "file_path = os.path.join(output_path, \"canais_removidos.xlsx\")\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "else:\n",
    "    df = pd.DataFrame(columns=[\"Genotype\", \"Animal\", \"Anesthesia_Level\", \"Removed_Channels\"])\n",
    "\n",
    "genotype = str(genotype).strip()\n",
    "animal = str(animal).strip()\n",
    "anesthesia_level = str(anesthesia_level).strip()\n",
    "\n",
    "df[\"Genotype\"] = df[\"Genotype\"].astype(str).str.strip()\n",
    "df[\"Animal\"] = df[\"Animal\"].astype(str).str.strip()\n",
    "df[\"Anesthesia_Level\"] = df[\"Anesthesia_Level\"].astype(str).str.strip()\n",
    "\n",
    "df = df.loc[~((df[\"Genotype\"] == genotype) & \n",
    "              (df[\"Animal\"] == animal) & \n",
    "              (df[\"Anesthesia_Level\"] == anesthesia_level))]\n",
    "\n",
    "nova_linha = pd.DataFrame([{\n",
    "    \"Genotype\": genotype,\n",
    "    \"Animal\": animal,\n",
    "    \"Anesthesia_Level\": anesthesia_level,\n",
    "    \"Removed_Channels\": removed_channels_str\n",
    "}])\n",
    "\n",
    "df = pd.concat([df, nova_linha], ignore_index=True)\n",
    "\n",
    "df = df.sort_values(by=[\"Genotype\", \"Animal\", \"Anesthesia_Level\"]).reset_index(drop=True)\n",
    "\n",
    "df.to_excel(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63]\n",
      "[37]\n"
     ]
    }
   ],
   "source": [
    "idx_ch_47=np.where(map==47)[0]\n",
    "idx_ch_48=np.where(map==48)[0]\n",
    "# idx_ch_48=map.index(48)\n",
    "print(idx_ch_47)\n",
    "print(idx_ch_48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.fft import fft\n",
    "\n",
    "# channel_idx =31\n",
    "# data_filter_ch=data_filter[channel_idx-1]\n",
    "# #data=butter_bandpass_filter(data=all_data[:,19]*.195, lowcut=300, highcut=3000, fs=sample_rate, order=4)\n",
    "\n",
    "# raw_data_to_plot = mem_map_data[:, map[channel_idx - 1]] * .195\n",
    "# filtered_data_to_plot = data_filter[:, channel_idx - 1]\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(2,1, figsize=(15, 5))\n",
    "# ax[0].plot(time,mem_map_data[int(ti*sample_rate):int(tf*sample_rate),map[channel_idx-1]]*.195,\"k\")\n",
    "# ax[0].set_xticks([])\n",
    "# ax[0].set_title('Raw data', fontsize=23)\n",
    "# ax[0].set_ylabel('amplitude [uV]', fontsize=16)\n",
    "# ax[0].tick_params(labelsize=12)\n",
    "\n",
    "# ax[1].plot(time,data_filter[int(ti * sample_rate):int(tf * sample_rate), channel_idx - 1],\"k\",lw=.5)#\n",
    "# ax[1].set_title('Filter data [300 Hz to 3000 Hz]', fontsize=23)\n",
    "# ax[1].set_xlabel('time [s]', fontsize=20)\n",
    "# ax[1].set_ylabel('amplitude [uV]', fontsize=16)\n",
    "# ax[1].tick_params(labelsize=12)\n",
    "\n",
    "# thresh = -np.mean(np.abs(data_filter))\n",
    "# print(thresh)\n",
    "# plt.axhline(y=thresh, color='r', linestyle='--', label='threshold')\n",
    "\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# fig = plt.figure(figsize=(13, 3))\n",
    "# N=len(data_filter[:,31-1])\n",
    "# T=1.0/sample_rate\n",
    "# x=np.linspace(0.0,N*T,N,endpoint=False)\n",
    "# yf=fft(data_filter[:,31-1])\n",
    "# xf=np.fft.fftfreq(N,T)[:N//2]\n",
    "# plt.plot(xf,2.0/N*np.abs(yf[0:N//2]))\n",
    "# plt.xlim(0,100)\n",
    "# plt.grid()\n",
    "\n",
    "# plt.title(\"Análise Espectral do Canal\")\n",
    "# plt.xlabel(\"Frequência (Hz)\")\n",
    "# plt.ylabel(\"Magnitude\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C=aj.calc_coh_from_dat (dat_filename,num_channels,sample_rate, t0=58) \n",
    "# plt.imshow(C+C.T)\n",
    "# plt.colorbar(label=\"Coherence\")\n",
    "# plt.xlabel ('Channel')\n",
    "# plt.ylabel ('Channel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels_for_phase_analysis = [2,7,12,18,23,29,34,39,44,50,55,61]\n",
    "\n",
    "\n",
    "# new_channels_for_phase_analysis = []\n",
    "\n",
    "# for ch_idx in channels_for_phase_analysis:\n",
    "#     if a[ch_idx] == 1:  \n",
    "#         new_channels_for_phase_analysis.append(ch_idx)\n",
    "#         continue\n",
    "\n",
    "#     found_replacement = False\n",
    "#     if ch_idx % 2 == 0:  \n",
    "#         for i in range(1, len(a)):  \n",
    "#             next_ch = ch_idx + i\n",
    "#             if next_ch < len(a) and a[next_ch] == 1:  \n",
    "#                 new_channels_for_phase_analysis.append(next_ch)\n",
    "#                 found_replacement = True\n",
    "#                 break\n",
    "#     else:  \n",
    "#         for i in range(1, len(a)):  \n",
    "#             prev_ch = ch_idx - i\n",
    "#             if prev_ch >= 0 and a[prev_ch] == 1:  \n",
    "#                 new_channels_for_phase_analysis.append(prev_ch)\n",
    "#                 found_replacement = True\n",
    "#                 break\n",
    "\n",
    "#     if not found_replacement:\n",
    "#         new_channels_for_phase_analysis.append(ch_idx)\n",
    "\n",
    "# channels_for_phase_analysis = new_channels_for_phase_analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hip_shank1': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'hip_shank2': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'hip_shank3': [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], 'pfc_shank1': [32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'pfc_shank2': [42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], 'pfc_shank3': [53, 54, 55, 56, 57, 58, 59, 60, 61, 62]}\n"
     ]
    }
   ],
   "source": [
    "shank_sizes = [10, 11, 11, 10, 11, 11]\n",
    "labels = ['hip_shank1', 'hip_shank2', 'hip_shank3', 'pfc_shank1', 'pfc_shank2', 'pfc_shank3']\n",
    "\n",
    "index_map = {}\n",
    "current_index = 0\n",
    "global_index = 0\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    size = shank_sizes[i]\n",
    "    active = a[global_index:global_index + size]\n",
    "    removed = active.count(0)\n",
    "    index_map[label] = list(range(current_index, current_index + size - removed))\n",
    "    current_index += size - removed\n",
    "    global_index += size\n",
    "\n",
    "print(index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 7, 12, 18, 23, 29, 34, 39, 44, 50, 55, 61]\n",
      "[24, 31, 22, 27, 14, 0, 56, 63, 54, 59, 46, 32]\n"
     ]
    }
   ],
   "source": [
    "channels_for_phase_analysis = []\n",
    "labels = ['hip_shank1', 'hip_shank2', 'hip_shank3', 'pfc_shank1', 'pfc_shank2', 'pfc_shank3']\n",
    "\n",
    "original_ranges = {\n",
    "    'hip_shank1': list(range(0, 10)),  \n",
    "    'hip_shank2': list(range(10, 21)),  \n",
    "    'hip_shank3': list(range(21, 32)),\n",
    "    'pfc_shank1': list(range(32, 42)),   \n",
    "    'pfc_shank2': list(range(42, 53)),\n",
    "    'pfc_shank3': list(range(53, 64))   \n",
    "}\n",
    "\n",
    "channels_for_phase_analysis = [2, 7, 12, 18, 23, 29, 34, 39, 44, 50, 55, 61]\n",
    "adjusted_channels = []\n",
    "\n",
    "for i, ch in enumerate(channels_for_phase_analysis):\n",
    "    \n",
    "    decremento = sum(1 for r in idx_removidos if r < ch)\n",
    "    ch_corrigido = ch - decremento\n",
    "\n",
    "    if ch_corrigido not in idx_validos:\n",
    "        \n",
    "        found = False\n",
    "        if i % 2 == 0:  \n",
    "            offset = 1\n",
    "            while not found and (ch_corrigido - offset) >= 0:\n",
    "                candidato = ch_corrigido - offset\n",
    "                if candidato in idx_validos:\n",
    "                    ch_corrigido = candidato\n",
    "                    found = True\n",
    "                offset += 1\n",
    "        else: \n",
    "            offset = 1\n",
    "            while not found and (ch_corrigido + offset) < len(idx_validos):\n",
    "                candidato = ch_corrigido + offset\n",
    "                if candidato in idx_validos:\n",
    "                    ch_corrigido = candidato\n",
    "                    found = True\n",
    "                offset += 1\n",
    "\n",
    "    adjusted_channels.append(ch_corrigido)\n",
    "\n",
    "channels_for_phase_analysis = adjusted_channels\n",
    "\n",
    "print(channels_for_phase_analysis)\n",
    "print([map_removido[i] for i in channels_for_phase_analysis])\n",
    "\n",
    "output_path = r\"C:\\Users\\Medicina\\MEOCloud\\Astrogang_Ephys\\ag_PatriciaAzenha\\Análise dados\\Canais escolhidos_t\"\n",
    "output_path=os.path.join(output_path, set_folder)\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "file_path = os.path.join(output_path, \"canais_escolhidos.xlsx\")\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "else:\n",
    "    df = pd.DataFrame(columns=[\"Genotype\", \"Animal\", \"Anesthesia_Level\", \"Selected_Channels\"])\n",
    "\n",
    "df[\"Genotype\"] = df[\"Genotype\"].astype(str).str.strip()\n",
    "df[\"Animal\"] = df[\"Animal\"].astype(str).str.strip()\n",
    "df[\"Anesthesia_Level\"] = df[\"Anesthesia_Level\"].astype(str).str.strip()\n",
    "\n",
    "\n",
    "df = df.loc[~((df[\"Genotype\"] == genotype) & \n",
    "              (df[\"Animal\"] == animal) & \n",
    "              (df[\"Anesthesia_Level\"] == anesthesia_level))]\n",
    "\n",
    "\n",
    "selected_channels_str = \", \".join(str(ch) for ch in channels_for_phase_analysis)\n",
    "\n",
    "\n",
    "nova_linha = pd.DataFrame([{\n",
    "    \"Genotype\": genotype,\n",
    "    \"Animal\": animal,\n",
    "    \"Anesthesia_Level\": anesthesia_level,\n",
    "    \"Selected_Channels\": selected_channels_str\n",
    "}])\n",
    "\n",
    "\n",
    "df = pd.concat([df, nova_linha], ignore_index=True)\n",
    "\n",
    "df = df.sort_values(by=[\"Genotype\", \"Animal\", \"Anesthesia_Level\"]).reset_index(drop=True)\n",
    "\n",
    "df.to_excel(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47]\n",
      "[2, 7, 12, 18, 23, 29, 34, 39, 44, 50, 55, 61]\n",
      "{'hip_shank1': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'hip_shank2': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'hip_shank3': [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], 'pfc_shank1': [32, 33, 34, 35, 36, 37, 38, 39, 40, 41], 'pfc_shank2': [42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], 'pfc_shank3': [53, 54, 55, 56, 57, 58, 59, 60, 61, 62]}\n"
     ]
    }
   ],
   "source": [
    "print(canais_removidos)\n",
    "print(channels_for_phase_analysis)\n",
    "# print(new_channels_for_phase_analysis)\n",
    "print(index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hip_shank1_inf': [0, 1, 2, 3, 4], 'hip_shank1_sup': [5, 6, 7, 8, 9], 'hip_shank2_inf': [10, 11, 12, 13, 14], 'hip_shank2_sup': [15, 16, 17, 18, 19, 20], 'hip_shank3_inf': [21, 22, 23, 24, 25], 'hip_shank3_sup': [26, 27, 28, 29, 30, 31], 'pfc_shank1_inf': [32, 33, 34, 35, 36], 'pfc_shank1_sup': [37, 38, 39, 40, 41], 'pfc_shank2_inf': [42, 43, 44, 45, 46], 'pfc_shank2_sup': [47, 48, 49, 50, 51, 52], 'pfc_shank3_inf': [53, 54, 55, 56, 57], 'pfc_shank3_sup': [58, 59, 60, 61, 62]}\n"
     ]
    }
   ],
   "source": [
    "shank_sizes = [5, 5, 5, 6, 5, 6, 5, 5, 5, 6, 5, 6]\n",
    "\n",
    "labels = [\n",
    "    'hip_shank1_inf', 'hip_shank1_sup',\n",
    "    'hip_shank2_inf', 'hip_shank2_sup',\n",
    "    'hip_shank3_inf', 'hip_shank3_sup',\n",
    "    'pfc_shank1_inf', 'pfc_shank1_sup',\n",
    "    'pfc_shank2_inf', 'pfc_shank2_sup',\n",
    "    'pfc_shank3_inf', 'pfc_shank3_sup'\n",
    "]\n",
    "index_map_tb = {}\n",
    "current_index = 0\n",
    "global_index = 0\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    size = shank_sizes[i]\n",
    "    active = a[global_index:global_index + size]\n",
    "    removed = active.count(0)\n",
    "    index_map_tb[label] = list(range(current_index, current_index + size - removed))\n",
    "    current_index += size - removed\n",
    "    global_index += size\n",
    "\n",
    "\n",
    "\n",
    "print(index_map_tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power Spectral Density per shank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Astrogang Ephys_Patricia\\PLOTS\\Set 119 - IP3R2KO\\WT\\A1\\PSD_by_shank\n",
      "caaminho: D:\\Astrogang Ephys_Patricia\\PLOTS\\Set 119 - IP3R2KO\\WT\\A1\\PSD_by_shank\\WT_2.5_PSD_by_shank_last5min.png\n",
      "map_removido [19, 18, 24, 17, 23, 16, 21, 31, 20, 30, 25, 7, 22, 12, 29, 11, 28, 10, 27, 8, 26, 2, 3, 14, 6, 13, 9, 1, 5, 0, 4, 15, 51, 50, 56, 49, 55, 48, 53, 63, 52, 62, 57, 39, 54, 44, 61, 43, 60, 42, 59, 40, 58, 34, 35, 46, 38, 45, 41, 33, 37, 32, 36]\n",
      "tamanho map 63\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# path_map = {\n",
    "#     ('KO', 'B0'): os.path.join(base_dir, \"KO_B0\", \"Power_shank\"),\n",
    "#     ('KO', 'B1'): os.path.join(base_dir, \"KO_B1\", \"Power_shank\"),\n",
    "#     ('WT', 'A0'): os.path.join(base_dir, \"WT_A0\", \"Power_shank\"),\n",
    "#     ('WT', 'A1'): os.path.join(base_dir, \"WT_A1\", \"Power_shank\")\n",
    "# }\n",
    "\n",
    "\n",
    "# save_path = path_map.get((genotype, animal), base_dir)\n",
    "# file_name = f\"{genotype}_{anesthesia_level}_PSD_by_shank_last5min.png\"\n",
    "# file_path = os.path.join(save_path, file_name)\n",
    "\n",
    "save_path = os.path.join(base_dir, genotype, animal, \"PSD_by_shank\")\n",
    "print(save_path)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "file_name = f\"{genotype}_{anesthesia_level}_PSD_by_shank_last5min.png\"\n",
    "# file_name = f\"{genotype}_{anesthesia_level}_PSD_by_allshank_last5.png\"\n",
    "file_path = os.path.join(save_path, file_name)\n",
    "print(f'caaminho: {file_path}')\n",
    "\n",
    "# # # # # ORIGINAL \n",
    "# index_map = {\n",
    "#     'hip_shank1': list(range(0, 10)),  # Canais 0 a 9\n",
    "#     'hip_shank2': list(range(10, 21)),  # Canais 10 a 20\n",
    "#     'hip_shank3': list(range(21, 32)),\n",
    "#     'pfc_shank1': list(range(32, 42)),   # Canais 21 a 31\n",
    "#     'pfc_shank2': list(range(42, 53)),\n",
    "#     'pfc_shank3': list(range(53, 64))   # Canais 32 a 42\n",
    "# }\n",
    "\n",
    "# ##Canais removidos\n",
    "# index_map = {\n",
    "#     'hip_shank1': list(range(0, 10)),  # Canais 0 a 9\n",
    "#     'hip_shank2': list(range(10, 21)),  # Canais 10 a 20\n",
    "#     'hip_shank3': list(range(21, 32)),\n",
    "#     'pfc_shank1': list(range(32, 41)),   # Canais 21 a 31\n",
    "#     'pfc_shank2': list(range(41, 52)),\n",
    "#     'pfc_shank3': list(range(52, 62))   # Canais 32 a 42\n",
    "# }\n",
    "\n",
    "\n",
    "titles = ['Shank 1', 'Shank 2', 'Shank 3', 'Shank 1', 'Shank 2', 'Shank 3']\n",
    "#### map_removido = np.delete(map, np.where(np.isin(map, [47, 48])))\n",
    "print('map_removido',map_removido)\n",
    "print('tamanho map',len(map_removido))\n",
    "\n",
    "def plot_shank_data(data_to_plot, index_mapping, sfs, nps, nvl, auxmin, auxmax, step, subsam, filepath,mapp):\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(15, 15))\n",
    "\n",
    "    # Adicionando títulos gerais para as colunas\n",
    "    fig.text(0.25, 0.95, \"Hippocampus\", fontsize=16, fontweight='bold', ha='center')\n",
    "    fig.text(0.75, 0.95, \"Prefrontal Cortex\", fontsize=16, fontweight='bold', ha='center')\n",
    "\n",
    "    titles = ['Shank 1', 'Shank 2', 'Shank 3']\n",
    "    hip_keys = ['hip_shank1', 'hip_shank2', 'hip_shank3']\n",
    "    pfc_keys = ['pfc_shank1', 'pfc_shank2', 'pfc_shank3']\n",
    "\n",
    "    \n",
    "    for i in range(3):  \n",
    "        for j in range(2):  \n",
    "            ax = axs[i, j]\n",
    "            key = hip_keys[i] if j == 0 else pfc_keys[i]  \n",
    "            shank_indices = index_mapping[key]\n",
    "            shank = data_to_plot[:, shank_indices]  \n",
    "            \n",
    "            for channel in range(shank.shape[1]):\n",
    "                canal_original=mapp[shank_indices[channel]]\n",
    "                sinal = shank[:, channel] * 0.195  \n",
    "                f, Pxx = signal.welch(sinal, sfs, nperseg=nps, noverlap=nvl)\n",
    "                canais_escolhidos=[mapp[i] for i in channels_for_phase_analysis ]\n",
    "                if canal_original in canais_escolhidos:\n",
    "                    ax.plot(f,Pxx,label=f'Channel {canal_original}',linewidth=3,color='blue')\n",
    "                else:\n",
    "                    ax.plot(f, Pxx, label=f'Channel {canal_original}',linewidth=1.0,linestyle='--', color='grey')\n",
    "\n",
    "            ax.set_xlabel('Frequency (Hz)')\n",
    "            \n",
    "            ax.set_ylabel('Power')\n",
    "            ax.legend()\n",
    "            ax.set_title(titles[i], fontsize=12)\n",
    "            ax.grid(axis='x', which='major', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "            ax.set_xticks(range(auxmin, auxmax + 1, step))  \n",
    "            ax.set_xlim([auxmin, auxmax])\n",
    "\n",
    "            \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.9])  \n",
    "    plt.savefig(filepath)\n",
    "    plt.close()\n",
    "    print(f\"Imagem guardada em: {filepath}\")\n",
    "\n",
    "freq_min = 0\n",
    "freq_max = 40\n",
    "step_f = 5\n",
    "\n",
    "# plot_shank_data(data_filter, index_map, SFs, NPS, NVL, freq_min, freq_max, step_f, sub_sampling, file_path,map_removido)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Astrogang Ephys_Patricia\\PLOTS\\Set 119 - IP3R2KO\\WT\\A1\\PSD_by_shank\n",
      "caaminho: D:\\Astrogang Ephys_Patricia\\PLOTS\\Set 119 - IP3R2KO\\WT\\A1\\PSD_by_shank\\WT_2.5_PSD_by_shank_sup_inf_last5min.png\n",
      "600.0\n"
     ]
    }
   ],
   "source": [
    "save_path = os.path.join(base_dir, genotype, animal, \"PSD_by_shank\")\n",
    "print(save_path)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "file_name = f\"{genotype}_{anesthesia_level}_PSD_by_shank_sup_inf_last5min.png\"\n",
    "file_path = os.path.join(save_path, file_name)\n",
    "print(f'caaminho: {file_path}')\n",
    "sub_sampling=50   \n",
    "SFs=30000/sub_sampling \n",
    "print(SFs)\n",
    "\n",
    "NPS =1200\n",
    "NVL = NPS//2 \n",
    "\n",
    "\n",
    "\n",
    "# index_map = {\n",
    "#     'hip_shank1_inf': list(range(0, 5)),\n",
    "#     'hip_shank1_sup': list(range(5, 10)),  \n",
    "#     'hip_shank2_inf': list(range(10, 15)),\n",
    "#     'hip_shank2_sup': list(range(15, 21)),\n",
    "#     'hip_shank3_inf': list(range(21, 26)),\n",
    "#     'hip_shank3_sup': list(range(26, 32)),\n",
    "#     'pfc_shank1_inf': list(range(32, 37)),\n",
    "#     'pfc_shank1_sup': list(range(37, 41)), \n",
    "#     'pfc_shank2_inf': list(range(41, 47)),\n",
    "#     'pfc_shank2_sup': list(range(47, 52)),\n",
    "#     'pfc_shank3_inf': list(range(52, 58)),\n",
    "#     'pfc_shank3_sup': list(range(58, 62))   \n",
    "# }\n",
    "\n",
    "\n",
    "##### map_removido = np.delete(map, np.where(np.isin(map, [47, 48])))\n",
    "\n",
    "\n",
    "def plot_shank_data(data_to_plot, index_mapping, sfs, nps, nvl, auxmin, auxmax, step, subsam, filepath,mapp):\n",
    "    fig, axs = plt.subplots(6, 2, figsize=(15, 20)) \n",
    "\n",
    "   \n",
    "    fig.text(0.25, 0.95, \"Hippocampus\", fontsize=16, fontweight='bold', ha='center')\n",
    "    fig.text(0.75, 0.95, \"Prefrontal Cortex\", fontsize=16, fontweight='bold', ha='center')\n",
    "\n",
    "    \n",
    "    hip_keys = [\n",
    "        'hip_shank1_inf', 'hip_shank1_sup',\n",
    "        'hip_shank2_inf', 'hip_shank2_sup',\n",
    "        'hip_shank3_inf', 'hip_shank3_sup'\n",
    "    ]\n",
    "    \n",
    "    pfc_keys = [\n",
    "        'pfc_shank1_inf', 'pfc_shank1_sup',\n",
    "        'pfc_shank2_inf', 'pfc_shank2_sup',\n",
    "        'pfc_shank3_inf', 'pfc_shank3_sup'\n",
    "    ]\n",
    "\n",
    "    titles = [\n",
    "        'Shank 1 - Inferior', 'Shank 1 - Superior',\n",
    "        'Shank 2 - Inferior', 'Shank 2 - Superior',\n",
    "        'Shank 3 - Inferior', 'Shank 3 - Superior'\n",
    "    ]\n",
    "\n",
    "    \n",
    "    for i in range(6):  \n",
    "        for j in range(2): \n",
    "            ax = axs[i, j]\n",
    "            key = hip_keys[i] if j == 0 else pfc_keys[i]  \n",
    "            shank_indices = index_mapping[key]\n",
    "            shank = data_to_plot[:, shank_indices]  \n",
    "            \n",
    "            for channel in range(shank.shape[1]):\n",
    "                sinal = shank[:, channel] * 0.195  \n",
    "                f, Pxx = signal.welch(sinal, sfs, nperseg=nps, noverlap=nvl)\n",
    "                ax.plot(f, Pxx, label=f'Channel {mapp[shank_indices[channel]]}')\n",
    "\n",
    "            ax.set_xlabel('Frequency (Hz)')\n",
    "            ax.set_ylabel('Power')\n",
    "            ax.legend()\n",
    "            ax.set_title(titles[i], fontsize=12)\n",
    "            ax.grid(axis='x', which='major', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "            ax.set_xticks(range(auxmin, auxmax + 1, step))  \n",
    "            ax.set_xlim([auxmin, auxmax])\n",
    "            \n",
    "            \n",
    "            ax.tick_params(labelbottom=True, labelleft=True)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])  \n",
    "    plt.savefig(filepath)\n",
    "    plt.close()\n",
    "    print(f\"Imagem guardada em: {filepath}\")\n",
    "\n",
    "freq_min = 0\n",
    "freq_max = 40\n",
    "step_f = 5\n",
    "\n",
    "# plot_shank_data(data_filter, index_map_tb, SFs, NPS, NVL, freq_min, freq_max, step_f, sub_sampling, file_path,map_removido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180000, 62)\n"
     ]
    }
   ],
   "source": [
    "print(data_filter.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar Excel com valores dos espetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel guardado em: C:\\Users\\Medicina\\MEOCloud\\Astrogang_Ephys\\ag_PatriciaAzenha\\Análise dados\\Outputs\\Set 119 - IP3R2KO\\Analise LFP\\Excel Final\\Valores PSD\\WT\\A1\\2.5\\PSD_all_channels.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "\n",
    "def save_spectrum_excel(data_to_plot, map_list, sfs, nps, nvl, subsam, base_dir, animal, concentracao):\n",
    "    all_data = []\n",
    "    num_channels = data_to_plot.shape[1]\n",
    "\n",
    "    for i in range(num_channels):\n",
    "        sinal = data_to_plot[:, i]\n",
    "        f, Pxx = signal.welch(sinal, sfs, nperseg=nps, noverlap=nvl)\n",
    "        canal_nome = f\"{map_list[i]}\"\n",
    "        for freq, power in zip(f, Pxx):\n",
    "            all_data.append([canal_nome, freq, power])\n",
    "\n",
    "    df = pd.DataFrame(all_data, columns=[\"Channel\", \"Frequency (Hz)\", \"Power\"])\n",
    "\n",
    "    save_dir = os.path.join(base_dir,genotype, animal, f\"{concentracao}\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    file_name = f\"PSD_all_channels.xlsx\"\n",
    "    file_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "    df.to_excel(file_path, index=False)\n",
    "    print(f\"Excel guardado em: {file_path}\")\n",
    "\n",
    "\n",
    "excel_base = os.path.join(\n",
    "    r\"C:\\Users\\Medicina\\MEOCloud\\Astrogang_Ephys\\ag_PatriciaAzenha\\Análise dados\\Outputs\",\n",
    "    set_folder,\n",
    "    \"Analise LFP\",\n",
    "    \"Excel Final\",\"Valores PSD\"\n",
    ")\n",
    "\n",
    "save_spectrum_excel(data_filter, map_removido, SFs, NPS, NVL, sub_sampling, excel_base, animal, anesthesia_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power Spectral Density - Chosen Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# path_map = {\n",
    "#     ('KO', 'B0'): os.path.join(base_dir, \"KO_B0\", \"Coherence\"),\n",
    "#     ('KO', 'B1'): os.path.join(base_dir, \"KO_B1\", \"Coherence\"),\n",
    "#     ('WT', 'A0'): os.path.join(base_dir, \"WT_A0\", \"Coherence\"),\n",
    "#     ('WT', 'A1'): os.path.join(base_dir, \"WT_A1\", \"Coherence\")\n",
    "# }\n",
    "\n",
    "# # Define o caminho de salvamento, incluindo a subpasta \"PSD_by_shank\"\n",
    "# save_path = os.path.join(path_map.get((genotype, animal), base_dir), \"PSD_by_shank\")\n",
    "# os.makedirs(save_path, exist_ok=True)\n",
    "# file_name = f\"{genotype}_{anesthesia_level}_PSD_by_shank_last5min_chosen.png\"\n",
    "# file_path = os.path.join(save_path, file_name)\n",
    "\n",
    "animal_path = os.path.join(base_dir, genotype, animal)\n",
    "coherence_path = os.path.join(animal_path, \"Coherence\")\n",
    "psd_by_shank_path = os.path.join(coherence_path, \"PSD_by_shank-chosen\")\n",
    "os.makedirs(psd_by_shank_path, exist_ok=True)\n",
    "file_name = f\"{genotype}_{anesthesia_level}_PSD_by_shank_last5min_chosen.png\"\n",
    "file_path = os.path.join(psd_by_shank_path, file_name)\n",
    "\n",
    "\n",
    "\n",
    "sub_sampling=50   \n",
    "SFs=30000/sub_sampling \n",
    "print(SFs)\n",
    "\n",
    "NPS =1200 # length of the segment\n",
    "NVL = NPS//2 # number of points to overlap between segments\n",
    "\n",
    "# index_map = {\n",
    "#     'hip_shank1': [2,7],  # Canais 0 a 9\n",
    "#     'hip_shank2': [12,18],  # Canais 10 a 20\n",
    "#     'hip_shank3': [23,29],\n",
    "#     'pfc_shank1': [34,38],  # Canais 21 a 31\n",
    "#     'pfc_shank2': [43,49],\n",
    "#     'pfc_shank3': [54,61] # Canais 32 a 42\n",
    "# }\n",
    "index_map_chosen = {\n",
    "    'hip_shank1': [channels_for_phase_analysis[0], channels_for_phase_analysis[1]],\n",
    "    'hip_shank2': [channels_for_phase_analysis[2], channels_for_phase_analysis[3]],\n",
    "    'hip_shank3': [channels_for_phase_analysis[4], channels_for_phase_analysis[5]],\n",
    "    'pfc_shank1': [channels_for_phase_analysis[6], channels_for_phase_analysis[7]],\n",
    "    'pfc_shank2': [channels_for_phase_analysis[8], channels_for_phase_analysis[9]],\n",
    "    'pfc_shank3': [channels_for_phase_analysis[10], channels_for_phase_analysis[11]]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def plot_shank_data(data_to_plot, index_mapping, plot_titles, sfs, nps, nvl, auxmin, auxmax, step, subsam, filepath):\n",
    "#     fig, axs = plt.subplots(len(plot_titles), 1, figsize=(15, 30))\n",
    "#     a = 0\n",
    "#     for i, title in enumerate(plot_titles):\n",
    "#         ax = axs[i]\n",
    "#         shank_indices = index_mapping[title]  # Obter os índices dos canais\n",
    "#         shank = data_to_plot[:, shank_indices]  # Selecionar os canais de data_filter usando os índices\n",
    "\n",
    "#         num_channels = shank.shape[1]\n",
    "                \n",
    "#         for channel in range(num_channels):\n",
    "#             sinal = shank[:, channel] * 0.195  \n",
    "#             f, Pxx = signal.welch(sinal[:], sfs, nperseg=nps, noverlap=nvl)\n",
    "#             original_channel_label = map[shank_indices[channel]]\n",
    "#             ax.plot(f, Pxx, label=f'Channel {original_channel_label}')\n",
    "#             a += 1\n",
    "#         ax.set_xlabel('Frequency (Hz)')\n",
    "#         ax.set_ylabel('Power')\n",
    "#         ax.legend()\n",
    "#         ax.set_title(title)\n",
    "\n",
    "#         ax.grid(axis='x', which='major', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "#         ax.set_xticks(range(auxmin, auxmax + 1, step))  \n",
    "#         ax.set_xlim([auxmin, auxmax])\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     # plt.savefig(filepath)  \n",
    "#     # plt.close()  \n",
    "#     print(f\"Imagem guardada em: {filepath}\")\n",
    "\n",
    "def plot_shank_data(data_to_plot, index_mapping, sfs, nps, nvl, auxmin, auxmax, step, subsam, filepath):\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(15, 15))\n",
    "\n",
    "    \n",
    "    fig.text(0.25, 0.95, \"Hippocampus\", fontsize=16, fontweight='bold', ha='center')\n",
    "    fig.text(0.75, 0.95, \"Prefrontal Cortex\", fontsize=16, fontweight='bold', ha='center')\n",
    "\n",
    "    titles = ['Shank 1', 'Shank 2', 'Shank 3']\n",
    "    hip_keys = ['hip_shank1', 'hip_shank2', 'hip_shank3']\n",
    "    pfc_keys = ['pfc_shank1', 'pfc_shank2', 'pfc_shank3']\n",
    "\n",
    "    \n",
    "    for i in range(3):  \n",
    "        for j in range(2):  \n",
    "            ax = axs[i, j]\n",
    "            key = hip_keys[i] if j == 0 else pfc_keys[i]  \n",
    "            shank_indices = index_mapping[key]\n",
    "            shank = data_to_plot[:, shank_indices]  \n",
    "            \n",
    "            for channel in range(shank.shape[1]):\n",
    "                sinal = shank[:, channel] * 0.195  \n",
    "                f, Pxx = signal.welch(sinal, sfs, nperseg=nps, noverlap=nvl)\n",
    "                ax.plot(f, Pxx, label=f'Channel {map_removido[shank_indices[channel]]}')\n",
    "\n",
    "            ax.set_xlabel('Frequency (Hz)')\n",
    "            \n",
    "            ax.set_ylabel('Power')\n",
    "            ax.legend()\n",
    "            ax.set_title(titles[i], fontsize=12)\n",
    "            ax.grid(axis='x', which='major', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "            ax.set_xticks(range(auxmin, auxmax + 1, step))  \n",
    "            ax.set_xlim([auxmin, auxmax])\n",
    "\n",
    "            \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.9])  \n",
    "    plt.savefig(filepath)\n",
    "    plt.close()\n",
    "    print(f\"Imagem guardada em: {filepath}\")\n",
    "freq_min = 0\n",
    "freq_max = 40\n",
    "step_f = 5\n",
    "# ####plot_shank_data(data_filter, index_map, titles, SFs, NPS, NVL, freq_min, freq_max, step_f,sub_sampling,file_path)\n",
    "# plot_shank_data(data_filter, index_map, SFs, NPS, NVL, freq_min, freq_max, step_f, sub_sampling, file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap per band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# path_map = {\n",
    "#     ('KO', 'B0'): os.path.join(base_dir, \"KO_B0\", \"Heatmap_shank_regions\"),\n",
    "#     ('KO', 'B1'): os.path.join(base_dir, \"KO_B1\", \"Heatmap_shank_regions\"),\n",
    "#     ('WT', 'A0'): os.path.join(base_dir, \"WT_A0\", \"Heatmap_shank_regions\"),\n",
    "#     ('WT', 'A1'): os.path.join(base_dir, \"WT_A1\", \"Heatmap_shank_regions\")\n",
    "# }\n",
    "\n",
    "\n",
    "# save_path = path_map.get((genotype, animal), base_dir)\n",
    "# file_name = f\"{genotype}_{anesthesia_level}_Heatmap_regions_last5min.png\"\n",
    "# file_path = os.path.join(save_path, file_name)\n",
    "\n",
    "animal_path = os.path.join(base_dir, genotype, animal)\n",
    "heatmap_path = os.path.join(animal_path, \"Heatmap_shank_regions\")\n",
    "os.makedirs(heatmap_path, exist_ok=True)\n",
    "\n",
    "file_name = f\"{genotype}_{anesthesia_level}_Heatmap_regions_last5min.png\"\n",
    "file_path = os.path.join(heatmap_path, file_name)\n",
    "\n",
    "\n",
    "freq_bands = {\n",
    "    'delta': (1, 4),\n",
    "    'theta': (4, 12),\n",
    "    'beta ': (12, 20),\n",
    "    'low gamma ': (20, 40)\n",
    "}\n",
    "\n",
    "# index_map = {\n",
    "#     'hip_shank1': list(range(0, 10)),  # Canais 0 a 9\n",
    "#     'hip_shank2': list(range(10, 21)),  # Canais 10 a 20\n",
    "#     'hip_shank3': list(range(21, 32)),\n",
    "#     'pfc_shank1': list(range(32, 42)),   # Canais 21 a 31\n",
    "#     'pfc_shank2': list(range(42, 53)),\n",
    "#     'pfc_shank3': list(range(53, 64))   # Canais 32 a 42\n",
    "# }\n",
    "\n",
    "\n",
    "def calculate_power_in_bands(f, psd, freq_bands):\n",
    "    # Calcula potência nas bandas de frequência definidas\n",
    "    power_in_bands = {}\n",
    "    for band, (start, end) in freq_bands.items():\n",
    "        # Calcula a potência na banda atual\n",
    "        band_power = np.trapz(psd[(f >= start) & (f <= end)], f[(f >= start) & (f <= end)])\n",
    "        power_in_bands[band] = band_power\n",
    "    return power_in_bands\n",
    "\n",
    "def calculate_and_plot_heatmaps(data_filter, index_map, sfs, nps, nvl, sub_sampling, file_path, freq_bands):\n",
    "    \n",
    "    # Separar mapas de índices para hipocampo e PFC\n",
    "    index_map_hippocampus = {k: v for k, v in index_map.items() if 'hip' in k}\n",
    "    index_map_pfc = {k: v for k, v in index_map.items() if 'pfc' in k}\n",
    "\n",
    "    proportions_hippocampus = {}\n",
    "    proportions_pfc = {}\n",
    "\n",
    "    # Calcular proporções para o Hipocampo\n",
    "    for region_map, proportions_dict in [(index_map_hippocampus, proportions_hippocampus)]:\n",
    "        for title, indices in region_map.items():\n",
    "            # Dividir os shanks em duas metades\n",
    "            bottom_indices = indices[:5]  # Canais inferiores (Bottom)\n",
    "            top_indices = indices[5:]      # Canais superiores (Top)\n",
    "\n",
    "            # Calcular PSD para as metades\n",
    "            psd_bottom = None\n",
    "            psd_top = None\n",
    "            \n",
    "            for index in bottom_indices:\n",
    "                signal = data_filter[:, index] * 0.195  \n",
    "                f, Pxx = welch(signal[:], sfs, nperseg=nps, noverlap=nvl)  \n",
    "                #print(Pxx)\n",
    "                if psd_bottom is None:\n",
    "                    psd_bottom = Pxx  \n",
    "                else:\n",
    "                    psd_bottom += Pxx  \n",
    "                # print(psd_bottom)\n",
    "\n",
    "            for index in top_indices:\n",
    "                signal = data_filter[:, index] * 0.195  \n",
    "                f, Pxx = welch(signal[:], sfs, nperseg=nps, noverlap=nvl)  \n",
    "                if psd_top is None:\n",
    "                    psd_top = Pxx  \n",
    "                else:\n",
    "                    psd_top += Pxx  \n",
    "\n",
    "            # Calcular a média do PSD para ambas as metades\n",
    "            \n",
    "\n",
    "            if psd_top is not None:\n",
    "                psd_top /= len(top_indices)\n",
    "                proportions_dict[f'{title} - Top'] = calculate_power_in_bands(f, psd_top, freq_bands)\n",
    "            \n",
    "            if psd_bottom is not None:\n",
    "                psd_bottom /= len(bottom_indices)\n",
    "                # print(psd_bottom)\n",
    "                proportions_dict[f'{title} - Bottom'] = calculate_power_in_bands(f, psd_bottom, freq_bands)\n",
    "\n",
    "\n",
    "\n",
    "    # Calcular proporções para o PFC\n",
    "    for region_map, proportions_dict in [(index_map_pfc, proportions_pfc)]:\n",
    "        for title, indices in region_map.items():\n",
    "            # Dividir os shanks em duas metades\n",
    "            \n",
    "            bottom_indices = indices[:5]  # Canais inferiores (Bottom)\n",
    "            top_indices = indices[5:]      # Canais superiores (Top)\n",
    "\n",
    "            # Calcular PSD para as metades\n",
    "            psd_bottom = None\n",
    "            psd_top = None\n",
    "            \n",
    "            for index in bottom_indices:\n",
    "                signal = data_filter[:, index] * 0.195  \n",
    "                f, Pxx = welch(signal[:], sfs, nperseg=nps, noverlap=nvl)  \n",
    "                if psd_bottom is None:\n",
    "                    psd_bottom = Pxx  \n",
    "                else:\n",
    "                    psd_bottom += Pxx  \n",
    "           \n",
    "            for index in top_indices:\n",
    "                signal = data_filter[:, index] * 0.195  \n",
    "                f, Pxx = welch(signal[:], sfs, nperseg=nps, noverlap=nvl)  \n",
    "                if psd_top is None:\n",
    "                    psd_top = Pxx  \n",
    "                else:\n",
    "                    psd_top += Pxx  \n",
    "\n",
    "            # Calcular a média do PSD para ambas as metades\n",
    "            \n",
    "\n",
    "            if psd_top is not None:\n",
    "                psd_top /= len(top_indices)\n",
    "                proportions_dict[f'{title} - Top'] = calculate_power_in_bands(f, psd_top, freq_bands)\n",
    "\n",
    "            if psd_bottom is not None:\n",
    "                psd_bottom /= len(bottom_indices)\n",
    "                proportions_dict[f'{title} - Bottom'] = calculate_power_in_bands(f, psd_bottom, freq_bands)\n",
    "\n",
    "    # Prepare heatmaps for Hippocampus\n",
    "    regions_hippocampus = list(proportions_hippocampus.keys())\n",
    "    print(regions_hippocampus)\n",
    "    heatmap_data_hippocampus = np.array([[proportions_hippocampus[region][band] for band in freq_bands] for region in regions_hippocampus])\n",
    "    \n",
    "    plt.figure(figsize=(30, 10))\n",
    "    # gs = plt.GridSpec(2, 1, height_ratios=[1, 1])  # Para dois heatmaps\n",
    "\n",
    "    # Heatmap para Hipocampo\n",
    "    ax1 = plt.subplot(1,2,1)\n",
    "    sns.heatmap(\n",
    "        heatmap_data_hippocampus, \n",
    "        cmap='coolwarm', \n",
    "        xticklabels=[f'{band} ({start}-{end} Hz)' for band, (start, end) in freq_bands.items()],  \n",
    "        yticklabels=[region.replace('hip_shank', '').replace('_', ' ') for region in regions_hippocampus],  \n",
    "        annot=False,\n",
    "        fmt=\".4f\", \n",
    "        cbar_kws={'label': 'µV²/Hz '}  \n",
    "    )\n",
    "    plt.title(f'PSD by Hippocampus', fontsize=22)\n",
    "    plt.xlabel('Frequency Bands', fontsize=18)\n",
    "    plt.ylabel('Shanks', fontsize=22)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=20)\n",
    "\n",
    "    cbar = ax1.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=22)\n",
    "    cbar.set_label('µV²/Hz', fontsize=18)\n",
    "\n",
    "    \n",
    "    regions_pfc = list(proportions_pfc.keys())\n",
    "    heatmap_data_pfc = np.array([[proportions_pfc[region][band] for band in freq_bands] for region in regions_pfc])\n",
    "    \n",
    "    # Heatmap para PFC\n",
    "    ax2 = plt.subplot(1,2,2)\n",
    "    sns.heatmap(\n",
    "        heatmap_data_pfc, \n",
    "        cmap='coolwarm', \n",
    "        xticklabels=[f'{band} ({start}-{end} Hz)' for band, (start, end) in freq_bands.items()],  \n",
    "        yticklabels=[region.replace('pfc_shank', '').replace('_', ' ') for region in regions_pfc],  \n",
    "        annot=False, \n",
    "        fmt=\".4f\",  \n",
    "        cbar_kws={'label': 'µV²/Hz '}  \n",
    "    )\n",
    "    plt.title(f'PSD by PFC', fontsize=22)\n",
    "    plt.xlabel('Frequency Bands', fontsize=18)\n",
    "    plt.ylabel('Shanks', fontsize=22)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=20)\n",
    "\n",
    "    cbar = ax2.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=22)\n",
    "    cbar.set_label('µV²/Hz', fontsize=18)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_path)  \n",
    "    plt.close()\n",
    "\n",
    "# proportions_result = calculate_and_plot_heatmaps(data_filter, index_map_tp, SFs, NPS, NVL, sub_sampling, file_path, freq_bands)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSD by regions of each shank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "save_path = os.path.join(base_dir, genotype, animal, \"PSD_regions\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "sub_sampling=50   \n",
    "SFs=30000/sub_sampling \n",
    "print(SFs)\n",
    "\n",
    "NPS =1200 # length of the segment\n",
    "NVL = NPS//2\n",
    "\n",
    "# ORIGINAL index_map = {\n",
    "#     'hip_shank1': list(range(0, 10)),  # Canais 0 a 9\n",
    "#     'hip_shank2': list(range(10, 21)),  # Canais 10 a 20\n",
    "#     'hip_shank3': list(range(21, 32)),\n",
    "#     'pfc_shank1': list(range(32, 42)),   # Canais 21 a 31\n",
    "#     'pfc_shank2': list(range(42, 53)),\n",
    "#     'pfc_shank3': list(range(53, 64))   # Canais 32 a 42\n",
    "# }\n",
    "\n",
    "# index_map = {\n",
    "#     'hip_shank1': list(range(0, 10)),  # Canais 0 a 9\n",
    "#     'hip_shank2': list(range(10, 21)),  # Canais 10 a 20\n",
    "#     'hip_shank3': list(range(21, 32)),\n",
    "#     'pfc_shank1': list(range(32, 41)),   # Canais 21 a 31\n",
    "#     'pfc_shank2': list(range(41, 52)),\n",
    "#     'pfc_shank3': list(range(52, 62))   # Canais 32 a 42\n",
    "# }\n",
    "\n",
    "\n",
    "freq_bands = {\n",
    "    'delta': (1, 4),\n",
    "    'theta': (4, 12),\n",
    "    'beta ': (12, 20),\n",
    "    'low gamma ': (20, 40)\n",
    "}\n",
    "\n",
    "\n",
    "def calcular_integral_psd_por_bandas(frequencias, psd, bandas):\n",
    "    integrais_por_banda = {}\n",
    "    for banda_nome, (banda_inferior, banda_superior) in bandas.items():\n",
    "        mask_banda = (frequencias >= banda_inferior) & (frequencias <= banda_superior)\n",
    "        frequencias_banda = frequencias[mask_banda]\n",
    "        psd_banda = psd[mask_banda]\n",
    "        \n",
    "        \n",
    "        if len(frequencias_banda) > 0 and len(psd_banda) > 0:\n",
    "            \n",
    "            integral_banda = np.trapz(psd_banda, frequencias_banda)#/(banda_superior-banda_inferior)\n",
    "            integrais_por_banda[banda_nome] = integral_banda\n",
    "        else:\n",
    "            integrais_por_banda[banda_nome] = 0  \n",
    "    return integrais_por_banda\n",
    "\n",
    "\n",
    "def calcular_psd_media(data, indices, sfs, nps, nvl):\n",
    "    psd_media = None\n",
    "    for index in indices:\n",
    "        sinal = data[:, index] * 0.195 \n",
    "        f, Pxx = signal.welch(sinal[:], sfs, nperseg=nps, noverlap=nvl)\n",
    "        \n",
    "        if psd_media is None:\n",
    "            psd_media = Pxx\n",
    "        else:\n",
    "            psd_media += Pxx\n",
    "\n",
    "    psd_media /= len(indices)\n",
    "    return f, psd_media\n",
    "3\n",
    "\n",
    "def calcular_psd_media_por_shank(data, indices, sfs, nps, nvl):\n",
    "    metade = len(indices)//2\n",
    "    metade_1_indices = indices[:metade]  \n",
    "    metade_2_indices = indices[metade:]  \n",
    "    \n",
    "\n",
    "    \n",
    "    frequencias_metade_1, psd_media_metade_1 = calcular_psd_media(data, metade_1_indices, sfs, nps, nvl)\n",
    "\n",
    "    \n",
    "    frequencias_metade_2, psd_media_metade_2 = calcular_psd_media(data, metade_2_indices, sfs, nps, nvl)\n",
    "\n",
    "    return frequencias_metade_1, psd_media_metade_1, psd_media_metade_2\n",
    "\n",
    "def plot_psd_e_integral_por_shank(data_filter, shank_names, SFs, NPS, NVL, sub_sampling, save_path, anesthesia_level, region_name):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 14))  \n",
    "\n",
    "\n",
    "\n",
    "    cores = {\n",
    "        'hip_shank1': {'Bottom': 'cornflowerblue', 'Top': 'mediumblue'},    \n",
    "        'hip_shank2': {'Bottom': 'palegreen', 'Top': 'limegreen'},        \n",
    "        'hip_shank3': {'Bottom': 'peachpuff', 'Top': 'red'},\n",
    "        'pfc_shank1': {'Bottom': 'violet', 'Top': 'purple'},       \n",
    "        'pfc_shank2': {'Bottom': 'khaki', 'Top': 'orange'},\n",
    "        'pfc_shank3': {'Bottom': 'pink', 'Top': 'crimson'}       \n",
    "    }\n",
    "\n",
    "    integrais_por_shank = {}\n",
    "\n",
    "    freq_bands = {\n",
    "        'delta': (1, 4),\n",
    "        'theta': (4, 12),\n",
    "        'beta ': (12, 20),\n",
    "        'low gamma ': (20, 40)\n",
    "    }\n",
    "\n",
    "    tabela_resultados = []\n",
    "\n",
    "    for shank_name in shank_names:\n",
    "        shank_indices = index_map[shank_name] \n",
    "        # print(shank_indices)\n",
    "        frequencias, psd_media_metade_1, psd_media_metade_2 = calcular_psd_media_por_shank(data_filter, shank_indices, SFs, NPS, NVL)\n",
    "\n",
    "        mask_metade_1 = frequencias <= 40\n",
    "        mask_metade_2 = frequencias <= 40\n",
    "\n",
    "        frequencias_metade_1 = frequencias[mask_metade_1]\n",
    "        psd_media_metade_1 = psd_media_metade_1[mask_metade_1]\n",
    "\n",
    "        frequencias_metade_2 = frequencias[mask_metade_2]\n",
    "        psd_media_metade_2 = psd_media_metade_2[mask_metade_2]\n",
    "\n",
    "        integrais_metade_1 = calcular_integral_psd_por_bandas(frequencias_metade_1, psd_media_metade_1, freq_bands)\n",
    "        integrais_metade_2 = calcular_integral_psd_por_bandas(frequencias_metade_2, psd_media_metade_2, freq_bands)\n",
    "\n",
    "        integrais_por_shank[shank_name] = {\n",
    "            'Bottom': integrais_metade_1,\n",
    "            'Top': integrais_metade_2\n",
    "        }\n",
    "\n",
    "        axes[0].plot(frequencias_metade_1, psd_media_metade_1, label=f'{shank_name} - Bottom', color=cores[shank_name]['Bottom'])\n",
    "        axes[0].plot(frequencias_metade_2, psd_media_metade_2, label=f'{shank_name} - Top', color=cores[shank_name]['Top'])\n",
    "\n",
    "        \n",
    "        for banda in freq_bands.keys():\n",
    "            integral_bottom = integrais_metade_1.get(banda, 0)\n",
    "            integral_top = integrais_metade_2.get(banda, 0)\n",
    "            tabela_resultados.append([shank_name, banda, 'Bottom', integral_bottom])\n",
    "            tabela_resultados.append([shank_name, banda, 'Top', integral_top])\n",
    "\n",
    "    bandas = list(integrais_por_shank[shank_names[0]]['Bottom'].keys())  # Obtém as bandas a partir de um shank\n",
    "    bottom_values = []\n",
    "    top_values = []\n",
    "\n",
    "    for shank in shank_names:\n",
    "        bottom_values.append([integrais_por_shank[shank]['Bottom'][banda] for banda in bandas])\n",
    "        top_values.append([integrais_por_shank[shank]['Top'][banda] for banda in bandas])\n",
    "\n",
    "    bottom_values = np.array(bottom_values)\n",
    "    top_values = np.array(top_values)\n",
    "\n",
    "    deslocamento_x = 0.3\n",
    "    largura_barra = 0.1  # Largura das barras\n",
    "\n",
    "    # Gráfico de Barras para as Integrais \n",
    "    for i, shank in enumerate(shank_names):\n",
    "        x_pos = np.arange(len(bandas)) + i * deslocamento_x  \n",
    "\n",
    "        # Desenhar as barras para  Bottom\n",
    "        axes[1].bar(x_pos - largura_barra / 2, bottom_values[i], width=largura_barra, \n",
    "                    color=cores[shank]['Bottom'], label=f'{shank} - Bottom', edgecolor='black')\n",
    "\n",
    "        # Desenhar as barras para  Top\n",
    "        axes[1].bar(x_pos + largura_barra / 2, top_values[i], width=largura_barra, \n",
    "                    color=cores[shank]['Top'], alpha=0.7, label=f'{shank} - Top', edgecolor='black')\n",
    "\n",
    "    axes[0].set_xlabel('Frequency (Hz)')\n",
    "    axes[0].set_ylabel('PSD (μV²/Hz)')\n",
    "    axes[0].set_title(f'Mean PSD - {region_name} {anesthesia_level}')\n",
    "    if region_name=='Hipocampo':\n",
    "\n",
    "        axes[0].set_ylim(-0.5, 325)\n",
    "    else:\n",
    "        axes[0].set_ylim(-0.5, 100)\n",
    "\n",
    "    axes[0].legend()\n",
    "    axes[0].grid()\n",
    "\n",
    "    axes[1].set_xlabel('Frequency Bands (Hz)', fontsize=14)\n",
    "    axes[1].set_ylabel('Integral (μV²)', fontsize=14)\n",
    "    axes[1].set_title('Integrals by Frequency Band', fontsize=16)\n",
    "\n",
    "    axes[1].set_xticks(np.arange(len(bandas)) + deslocamento_x * (len(shank_names) - 1) / 2)\n",
    "    axes[1].set_xticklabels(bandas)\n",
    "\n",
    "    axes[1].set_xlim(-0.5, len(bandas) - 1 + deslocamento_x * (len(shank_names) - 1) + 0.5)\n",
    "    if region_name=='Hipocampo':\n",
    "\n",
    "        axes[1].set_ylim(-0.5, 325)\n",
    "    else:\n",
    "        axes[1].set_ylim(-0.5, 100)\n",
    "\n",
    "    axes[1].legend(loc='upper left', bbox_to_anchor=(1, 1), title='Metades')\n",
    "    axes[1].grid(axis='y', linestyle='--')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    file_name = f\"{genotype}_{anesthesia_level}_{region_name}_Mean_and_Integrals_last5min.png\"\n",
    "    file_path = os.path.join(save_path, file_name)\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()\n",
    "\n",
    "    #Guardar o arquivo TXT\n",
    "    # txt_file = os.path.join(save_path, f\"{genotype}_{anesthesia_level}_{region_name}_Integrals_last5min.txt\")\n",
    "    # with open(txt_file, 'w') as f:\n",
    "    #     f.write(\"Shank\\tBanda\\tMetade\\tIntegral\\n\")  # Cabeçalhos\n",
    "    #     for linha in tabela_resultados:\n",
    "    #         # Escrever os valores no formato esperado\n",
    "    #         f.write(f\"{linha[0]}\\t{linha[1]}\\t{linha[2]}\\t{linha[3]:.4f}\\n\")\n",
    "\n",
    "    df_resultados = pd.DataFrame(tabela_resultados, columns=[\"Shank\", \"Banda\", \"Metade\", \"Integral\"])\n",
    "    excel_file = os.path.join(save_path, f\"{genotype}_{anesthesia_level}_{region_name}_Integrals_last5min.xlsx\")\n",
    "    df_resultados.to_excel(excel_file, index=False)\n",
    "\n",
    "    return integrais_por_shank\n",
    "\n",
    "\n",
    "\n",
    "# Execução para o Hipocampo e PFC\n",
    "shank_names_hipocampo = ['hip_shank1', 'hip_shank2', 'hip_shank3']\n",
    "shank_names_pfc = ['pfc_shank1','pfc_shank2','pfc_shank3']\n",
    "\n",
    "# Para o Hipocampo\n",
    "# plot_psd_e_integral_por_shank(data_filter, shank_names_hipocampo, SFs, NPS, NVL, sub_sampling, save_path, anesthesia_level, \"Hipocampo\")\n",
    "\n",
    "# # Para o PFC\n",
    "# plot_psd_e_integral_por_shank(data_filter, shank_names_pfc, SFs, NPS, NVL, sub_sampling, save_path, anesthesia_level, \"PFC\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw=mem_map_data[:,11]\n",
    "# f, t, Sxx = signal.spectrogram(raw[::sub_sampling]*.195, fs=SFs, window='hann', nperseg=NPS, noverlap=NVL)\n",
    "\n",
    "# freq_min = 0 \n",
    "# freq_max = 70\n",
    "# idx_freq = np.where((f >= freq_min) & (f <= freq_max))\n",
    "# f = f[idx_freq]\n",
    "# Sxx = Sxx[idx_freq, :][0]\n",
    "\n",
    "# plt.pcolormesh(t, f, 10 * np.log10(Sxx))  \n",
    "# plt.colorbar(label='Power (dB)')\n",
    "# plt.xlabel('Time (s)')\n",
    "# plt.ylabel('Frequency (Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPS = 1200 \n",
    "lowcut = 1  \n",
    "highcut = 40  \n",
    "\n",
    "channels_for_fft = [2, 7, 12, 18, 23, 29, 34, 40]\n",
    "\n",
    "def plot_fft(channel_data, channel_idx):\n",
    "    fft_result = np.fft.fft(channel_data, n=NPS)\n",
    "    frequencies = np.fft.fftfreq(NPS, d=1/SFs)\n",
    "\n",
    "    \n",
    "    magnitude = np.abs(fft_result)\n",
    "    phase = np.angle(fft_result)  \n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(frequencies[:NPS // 2], magnitude[:NPS // 2], color='blue')  \n",
    "    plt.title(f'FFT Magnitude for Channel {map[channel_idx]}')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.xlim([0, highcut])\n",
    "    plt.xticks(np.arange(lowcut, highcut + 1, 2))  \n",
    "    plt.grid()\n",
    "\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(frequencies[:NPS // 2], phase[:NPS // 2], color='orange')  \n",
    "    plt.title(f'FFT Phase (Radians) for Channel {map[channel_idx]}')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Phase (radians)')\n",
    "    plt.xlim([0, highcut])\n",
    "    plt.xticks(np.arange(lowcut, highcut + 1, 2)) \n",
    "    \n",
    "    \n",
    "    pi_ticks = [-2*np.pi, -np.pi, 0, np.pi, 2*np.pi]\n",
    "    pi_labels = [r'$-2\\pi$', r'$-\\pi$', '0', r'$\\pi$', r'$2\\pi$']\n",
    "    plt.yticks(pi_ticks, pi_labels)  \n",
    "    \n",
    "    plt.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "    path_map = {\n",
    "        ('KO', 'B0'): os.path.join(base_dir, \"KO_B0\", \"FFT\"), \n",
    "        ('KO', 'B1'): os.path.join(base_dir, \"KO_B1\", \"FFT\"), \n",
    "        ('WT', 'A0'): os.path.join(base_dir, \"WT_A0\", \"FFT\"), \n",
    "        ('WT', 'A1'): os.path.join(base_dir, \"WT_A1\", \"FFT\") \n",
    "    }\n",
    "    save_path = path_map.get((genotype, animal), base_dir)\n",
    "    anesthesia_folder = os.path.join(save_path, anesthesia_level)\n",
    "\n",
    "    file_name = f\"Channel_{map[channel_idx]}_last5min_.png\"\n",
    "    file_path = os.path.join(anesthesia_folder, file_name)\n",
    "    print(f'guardado em {file_path} ')\n",
    "\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "for channel_idx in channels_for_fft:\n",
    "    channel_data = data_filter[:, channel_idx]\n",
    "    #plot_fft(channel_data, channel_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coherence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Medicina\\AppData\\Local\\Temp\\ipykernel_7352\\1272371463.py:59: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 6))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import signal\n",
    "from itertools import combinations\n",
    "from matplotlib.patches import Patch\n",
    "from scipy.signal import hilbert\n",
    "\n",
    "freq_bands = {\n",
    "    'Delta': (1, 4),\n",
    "    'Theta': (4, 12),\n",
    "    'Beta': (12, 20),\n",
    "    'Low Gamma': (20, 40)\n",
    "}\n",
    "\n",
    "mean_amplitude_coh = {}\n",
    "mean_phase_coh = {}\n",
    "##### map_removido = np.delete(map, np.where(np.isin(map, [47, 48])))\n",
    "# print('map_removido',map_removido)\n",
    "\n",
    "def plot_coherence(data_filter, data1_idx, data2_idx, SFs):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for band_name, freq_band in freq_bands.items():\n",
    "        lowcut, highcut = freq_band\n",
    "        data1 = data_filter[:, data1_idx]\n",
    "        data2 = data_filter[:, data2_idx]\n",
    "\n",
    "        f, Pxx = signal.welch(data1, SFs, nperseg=NPS, noverlap=NVL)\n",
    "        f, Pyy = signal.welch(data2, SFs, nperseg=NPS, noverlap=NVL)\n",
    "        f, Pxy = signal.csd(data1, data2, SFs, nperseg=NPS, noverlap=NVL)\n",
    "\n",
    "        freq_indices = np.where((f >= lowcut) & (f <= highcut))\n",
    "        \n",
    "        # Coerência de amplitude\n",
    "        coh_amplitude = np.abs(Pxy[freq_indices]) ** 2 / (Pxx[freq_indices] * Pyy[freq_indices])\n",
    "        \n",
    "        \n",
    "        plt.plot(f[freq_indices], coh_amplitude, color='purple')  \n",
    "\n",
    "        \n",
    "        mean_coh_amp = np.mean(coh_amplitude)\n",
    "        channel_pair = (data1_idx, data2_idx)\n",
    "        if channel_pair not in mean_amplitude_coh:\n",
    "            mean_amplitude_coh[channel_pair] = {}\n",
    "        mean_amplitude_coh[channel_pair][band_name] = mean_coh_amp\n",
    "\n",
    "    plt.title(f\"Amplitude Coherence between Channels {map_removido[data1_idx]} - {map_removido[data2_idx]} (All Bands)\")\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.ylabel(\"Amplitude Coherence\")\n",
    "    plt.axhline(0, color='black', lw=0.8, ls='--')\n",
    "    plt.grid()\n",
    "    \n",
    "    save_plot(data1_idx, data2_idx, \"Amplitude\")  \n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_phase_coherence(data_filter, data1_idx, data2_idx, SFs):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for band_name, freq_band in freq_bands.items():\n",
    "        lowcut, highcut = freq_band\n",
    "        data1 = data_filter[:, data1_idx]\n",
    "        data2 = data_filter[:, data2_idx]\n",
    "\n",
    "        # f, Pxx = signal.welch(data1, SFs, nperseg=NPS, noverlap=NVL)\n",
    "        # f, Pyy = signal.welch(data2, SFs, nperseg=NPS, noverlap=NVL)\n",
    "        # f, Pxy = signal.csd(data1, data2, SFs, nperseg=NPS, noverlap=NVL)\n",
    "\n",
    "        freq_indices = np.where((f >= lowcut) & (f <= highcut))\n",
    "\n",
    "        sinal1 = butter_bandpass_filter(data1,lowcut,highcut,SFs)\n",
    "        sinal2 = butter_bandpass_filter(data2,lowcut,highcut,SFs)\n",
    "        angles1=(np.angle(hilbert(sinal1))) #obtenção do angulo usando a tranformada de hilbert que dá a fase instantânea\n",
    "        angles2=(np.angle(hilbert(sinal2)))\n",
    "        \n",
    "        # Coerência de fase\n",
    "        # phase_diff = np.angle(Pxy[freq_indices])\n",
    "        phase_diff=(angles2-angles1)\n",
    "\n",
    "        \n",
    "        # plt.plot(f[freq_indices], phase_diff, color='blue')  \n",
    "\n",
    "        \n",
    "        # mean_coh_phase = np.arctan2(np.mean(np.sin(phase_diff)), np.mean(np.cos(phase_diff)))\n",
    "        # mean_coh_phase=np.abs(np.mean(phase_diff))\n",
    "        mean_coh_phase=np.abs(np.mean(np.exp(1j * phase_diff)))\n",
    "\n",
    "        channel_pair = (data1_idx, data2_idx)\n",
    "        if channel_pair not in mean_phase_coh:\n",
    "            mean_phase_coh[channel_pair] = {}\n",
    "        mean_phase_coh[channel_pair][band_name] = mean_coh_phase\n",
    "\n",
    "    # plt.title(f\"Phase Coherence between Channels {map_removido[data1_idx]} - {map_removido[data2_idx]} (All Bands)\")\n",
    "    # plt.xlabel(\"Frequency (Hz)\")\n",
    "    # plt.ylabel(\"Phase Coherence \")\n",
    "    # plt.axhline(0, color='black', lw=0.8, ls='--')\n",
    "    # # plt.yticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$', r'$-\\pi/2$', r'0', r'$\\pi/2$', r'$\\pi$'])\n",
    "    # plt.grid()\n",
    "\n",
    "    # save_plot(data1_idx, data2_idx, \"Phase\")  \n",
    "    # plt.close()\n",
    "\n",
    "\n",
    "def save_plot(data1_idx, data2_idx, plot_type):\n",
    "    save_path = os.path.join(base_dir, genotype, animal, \"Coherence - teste\", anesthesia_level)\n",
    "    full_folder = os.path.join(save_path, plot_type, \"Full\")\n",
    "    os.makedirs(full_folder, exist_ok=True)\n",
    "\n",
    "    file_name = f\"COH_All_Bands - Channels {map_removido[data1_idx]} and {map_removido[data2_idx]}.png\"\n",
    "    file_path = os.path.join(full_folder, file_name)\n",
    "\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_mean_values_txt():\n",
    "    save_path = os.path.join(base_dir, genotype, animal, \"Coherence - teste - formula\", anesthesia_level)\n",
    "    mean_amplitude_folder = os.path.join(save_path, \"Amplitude\", \"Mean\")\n",
    "    mean_phase_folder = os.path.join(save_path, \"Phase\", \"Mean\")\n",
    "    os.makedirs(mean_amplitude_folder, exist_ok=True)\n",
    "    os.makedirs(mean_phase_folder, exist_ok=True)\n",
    "\n",
    "    \n",
    "    # with open(os.path.join(mean_amplitude_folder, \"COH_mean_amplitude_values.txt\"), \"w\") as amp_file:\n",
    "    #     amp_file.write(\"Channel Pair\\tBand\\tMean Amplitude\\n\")\n",
    "    #     for (ch1, ch2), bands in mean_amplitude_coh.items():\n",
    "    #         for band, mean_amp in bands.items():\n",
    "    #             amp_file.write(f\"{ch1}-{ch2}\\t{band}\\t{mean_amp}\\n\")\n",
    "    amp_data = []\n",
    "    for (ch1, ch2), bands in mean_amplitude_coh.items():\n",
    "        for band, mean_amp in bands.items():\n",
    "            amp_data.append([f\"{ch1}-{ch2}\", band, mean_amp])\n",
    "\n",
    "    amp_df = pd.DataFrame(amp_data, columns=[\"Channel Pair\", \"Band\", \"Mean Amplitude\"])\n",
    "    amp_file = os.path.join(mean_amplitude_folder, \"COH_mean_amplitude_values.xlsx\")\n",
    "    amp_df.to_excel(amp_file, index=False)\n",
    "\n",
    "\n",
    "    \n",
    "    # with open(os.path.join(mean_phase_folder, \"COH_mean_phase_values.txt\"), \"w\") as phase_file:\n",
    "    #     phase_file.write(\"Channel Pair\\tBand\\tMean Phase\\n\")\n",
    "    #     for (ch1, ch2), bands in mean_phase_coh.items():\n",
    "    #         for band, mean_phase in bands.items():\n",
    "    #             phase_file.write(f\"{ch1}-{ch2}\\t{band}\\t{mean_phase}\\n\")\n",
    "    phase_data = []\n",
    "    for (ch1, ch2), bands in mean_phase_coh.items():\n",
    "        for band, mean_phase in bands.items():\n",
    "            phase_data.append([f\"{ch1}-{ch2}\", band, mean_phase])\n",
    "\n",
    "    phase_df = pd.DataFrame(phase_data, columns=[\"Channel Pair\", \"Band\", \"Mean Phase\"])\n",
    "    phase_file = os.path.join(mean_phase_folder, \"COH_mean_phase_values.xlsx\")\n",
    "    phase_df.to_excel(phase_file, index=False)\n",
    "\n",
    "\n",
    "def plot_mean_amplitude_phase(channels, SFs):\n",
    "    save_path = os.path.join(base_dir, genotype, animal, \"Coherence - teste - formula\", anesthesia_level)\n",
    "    amplitude_mean_path = os.path.join(save_path, \"Amplitude\", \"Mean\")\n",
    "    phase_mean_path = os.path.join(save_path, \"Phase\", \"Mean\")\n",
    "    os.makedirs(amplitude_mean_path, exist_ok=True)\n",
    "    os.makedirs(phase_mean_path, exist_ok=True)\n",
    "\n",
    "    \n",
    "\n",
    "    ## CORES ORIGINAIS\n",
    "    # genComb_same_shank = {tuple(sorted(pair)) for pair in [(2,7), (12,18), (23,29), (34,38), (43,49), (54,61)]}\n",
    "    # genComb_same_probe = {tuple(sorted(pair)) for pair in [(2,12), (2,18), (2,23), (2,29), (7,12), (7,18), (7,23), \n",
    "    #                                                        (7,29), (12,23), (12,29), (18,23), (18,29), (34,43), (34,49), \n",
    "    #                                                        (34,54), (34,61), (38,43), (38,49), (38,54), (38,61), \n",
    "    #                                                        (43,54), (43,61), (49,54), (49,61)]}\n",
    "\n",
    "    # genComb_same_shank_hip = {tuple(sorted(pair)) for pair in [(2,7), (12,18), (23,29)]}\n",
    "    # genComb_same_shank_pfc = {tuple(sorted(pair)) for pair in [(34,38), (43,49), (54,61)]}\n",
    "    # genComb_same_probe_hip = {tuple(sorted(pair)) for pair in [(2,12), (2,18), (2,23), (2,29), (7,12), (7,18), (7,23), \n",
    "    #                                                            (7,29), (12,23), (12,29), (18,23), (18,29)]}\n",
    "    # genComb_same_probe_pfc = {tuple(sorted(pair)) for pair in [(34,43), (34,49),(34,54), (34,61), (38,43), (38,49), (38,54), (38,61), \n",
    "    #                                                            (43,54), (43,61), (49,54), (49,61)]}\n",
    "\n",
    "    genComb_same_shank_hip = {tuple(sorted((channels_for_phase_analysis[i], channels_for_phase_analysis[j])))\n",
    "                          for i, j in [(0, 1), (2, 3), (4, 5)]}\n",
    "\n",
    "    genComb_same_shank_pfc = {tuple(sorted((channels_for_phase_analysis[i], channels_for_phase_analysis[j])))\n",
    "                          for i, j in [(6, 7), (8, 9), (10, 11)]}\n",
    "\n",
    "    genComb_same_probe_hip = {tuple(sorted((channels_for_phase_analysis[i], channels_for_phase_analysis[j])))\n",
    "                          for i, j in [(0, 2), (0, 3), (0, 4), (0, 5), \n",
    "                                       (1, 2), (1, 3), (1, 4), (1, 5), \n",
    "                                       (2, 4), (2, 5), (3, 4), (3, 5)]}\n",
    "\n",
    "    genComb_same_probe_pfc = {tuple(sorted((channels_for_phase_analysis[i], channels_for_phase_analysis[j])))\n",
    "                          for i, j in [(6, 8), (6, 9), (6, 10), (6, 11), \n",
    "                                       (7, 8), (7, 9), (7, 10), (7, 11), \n",
    "                                       (8, 10), (8, 11), (9, 10), (9, 11)]}\n",
    "    # genComb_same_probe_hip_without_middle = {tuple(sorted((channels_for_phase_analysis[i], channels_for_phase_analysis[j])))\n",
    "    #                       for i, j in [(0, 4), (0, 5), (1, 4), (1, 5)]}\n",
    "\n",
    "    # genComb_same_probe_pfc_without_middle = {tuple(sorted((channels_for_phase_analysis[i], channels_for_phase_analysis[j])))\n",
    "    #                       for i, j in [(6, 10), (6, 11), (7, 10), (7, 11)]}\n",
    "\n",
    "\n",
    "    genComb = list(combinations(channels, r=2))\n",
    "\n",
    "    for band_name in freq_bands.keys():\n",
    "        \n",
    "        data_list = []\n",
    "        for ch1, ch2 in genComb:\n",
    "            sorted_pair = tuple(sorted((ch1, ch2)))\n",
    "\n",
    "            if sorted_pair in genComb_same_shank_hip:\n",
    "                colour=\"blue\"\n",
    "            elif sorted_pair in genComb_same_shank_pfc:\n",
    "                colour=\"lightsteelblue\"\n",
    "            elif sorted_pair in  genComb_same_probe_hip:\n",
    "                colour=\"green\"\n",
    "            elif sorted_pair in  genComb_same_probe_pfc:\n",
    "                colour=\"lightgreen\"\n",
    "            else:\n",
    "                colour=\"red\"\n",
    "\n",
    "            mean_amp = mean_amplitude_coh.get(sorted_pair, {}).get(band_name, 0)\n",
    "            mean_phase = mean_phase_coh.get(sorted_pair, {}).get(band_name, 0)\n",
    "            label = f\"{map_removido[ch1]}-{map_removido[ch2]}\"\n",
    "            data_list.append((colour, mean_amp, mean_phase, label))\n",
    "    # for band_name in freq_bands.keys():\n",
    "    #     grouped_data=[]\n",
    "        # for i in genComb:\n",
    "        #     # mean_amp_diffs=mean_amplitude_coh[((ch1, ch2))][band_name]\n",
    "        #     if i in genComb_same_shank:\n",
    "        #         colour=\"blue\"\n",
    "        #     elif i in genComb_same_probe:\n",
    "        #         colour=\"red\"\n",
    "        #     else:\n",
    "        #         colour=\"green\"\n",
    "        #     list_colours.append(colour)\n",
    "            # mean_amp = mean_amplitude_coh[(ch1, ch2)][band_name]\n",
    "            # mean_phase = mean_phase_coh[(ch1, ch2)][band_name]\n",
    "            # grouped_data.append((sorted_pair, colour, mean_amp, mean_phase, order))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # mean_amp_diffs = [mean_amplitude_coh[(ch1, ch2)][band_name] for ch1, ch2 in combinations(channels, 2)]\n",
    "        # mean_phase_diffs = [mean_phase_coh[(ch1, ch2)][band_name] for ch1, ch2 in combinations(channels, 2)]\n",
    "        # channel_labels = [f\"{map[ch1]}-{map[ch2]}\" for ch1, ch2 in combinations(channels, 2)]\n",
    "        color_order = {'blue':0,\"lightsteelblue\":1, 'red':2, 'green':3,\"lightgreen\": 4}\n",
    "        data_list.sort(key=lambda x: color_order[x[0]])\n",
    "        sorted_colours, sorted_mean_amp, sorted_mean_phase, sorted_labels = zip(*data_list)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        plt.figure(figsize=(20, 6))\n",
    "        plt.bar(sorted_labels, sorted_mean_amp,color=sorted_colours)\n",
    "        plt.title(f\"Mean Amplitude Coherence - {band_name}\")\n",
    "        plt.xlabel(\"Channel Pairs\")\n",
    "        plt.ylabel(\"Mean Amplitude Coherence\")\n",
    "        plt.axhline(0, color='black', lw=0.8, ls='--')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid()\n",
    "        legend_patches=[Patch(color='blue',label = 'Same shank HIP'),Patch(color='lightsteelblue',label = 'Same shank PFC'),Patch(color='red',label = 'Different Probe'),Patch(color='green',label = 'Different Shanks HIP '),Patch(color='lightgreen',label = 'Different Shanks PFC ')]\n",
    "        # plt.legend(handles=legend_patches, loc='upper right')\n",
    "        # plt.tight_layout()\n",
    "        plt.legend(handles=legend_patches, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])      \n",
    "        plt.savefig(os.path.join(amplitude_mean_path, f\"Coh Mean_Amplitude_{band_name}.png\"), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "        plt.figure(figsize=(20, 6))\n",
    "        plt.bar(sorted_labels,sorted_mean_phase,color=sorted_colours)\n",
    "        plt.title(f\"Mean Phase Coherence - {band_name}\")\n",
    "        plt.xlabel(\"Channel Pairs\")\n",
    "        plt.ylabel(\"Mean Phase Coherence \")\n",
    "        plt.ylim(0, 1)\n",
    "\n",
    "        plt.axhline(0, color='black', lw=0.8, ls='--')\n",
    "        # plt.yticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$', r'$-\\pi/2$', r'0', r'$\\pi/2$', r'$\\pi$'])\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid()\n",
    "        legend_patches=[Patch(color='blue',label = 'Same shank HIP'),Patch(color='lightsteelblue',label = 'Same shank PFC'),Patch(color='red',label = 'Different Probe'),Patch(color='green',label = 'Different Shanks in HIP '),Patch(color='lightgreen',label = 'Different Shanks in PFC ')]\n",
    "        # plt.legend(handles=legend_patches, loc='upper right')\n",
    "        # plt.tight_layout()\n",
    "        plt.legend(handles=legend_patches, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])      \n",
    "        plt.savefig(os.path.join(phase_mean_path, f\"Coh Mean_Phase_{band_name}.png\"), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "for data1_idx, data2_idx in combinations(channels_for_phase_analysis, 2):\n",
    "    plot_coherence(data_filter, data1_idx, data2_idx, SFs)\n",
    "\n",
    "\n",
    "for data1_idx, data2_idx in combinations(channels_for_phase_analysis, 2):\n",
    "    plot_phase_coherence(data_filter, data1_idx, data2_idx, SFs)\n",
    "\n",
    "\n",
    "plot_mean_amplitude_phase(channels_for_phase_analysis, SFs)\n",
    "save_mean_values_txt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 7, 12, 18, 23, 29, 34, 39, 44, 50, 55, 61]\n",
      "[47]\n"
     ]
    }
   ],
   "source": [
    "# channels_for_phase_analysis = [2,7,12,18,23,29,34,39,44,50,55,61]\n",
    "print(channels_for_phase_analysis)\n",
    "print(canais_removidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "print(NPS)\n",
    "print(NVL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dbwiuasmk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[678], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dbwiuasmk\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dbwiuasmk' is not defined"
     ]
    }
   ],
   "source": [
    "dbwiuasmk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram- Hilbert Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARA NAO APAGAR FICHEIROS DA FWHM\n",
    "from scipy.signal import hilbert\n",
    "from collections import defaultdict\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "#### map_removido = np.delete(map, np.where(np.isin(map, [47, 48])))\n",
    "\n",
    "\n",
    "def phase_consistency_histogram(data_filter, data1_idx, data2_idx, SFs, freq_band, band_name, num_bins=100):\n",
    "    data1 = data_filter[:, data1_idx]\n",
    "    data2 = data_filter[:, data2_idx]\n",
    "\n",
    "    lowcut, highcut = freq_band\n",
    "    data1_filtered = butter_bandpass_filter(data1, lowcut, highcut, SFs)\n",
    "    data2_filtered = butter_bandpass_filter(data2, lowcut, highcut, SFs)\n",
    "\n",
    "    analytic_signal1 = hilbert(data1_filtered)\n",
    "    analytic_signal2 = hilbert(data2_filtered)\n",
    "    phase1 = np.angle(analytic_signal1)\n",
    "    phase2 = np.angle(analytic_signal2)\n",
    "\n",
    "    phase_difference = np.angle(np.exp(1j * (phase1 - phase2))) \n",
    "\n",
    "    hist, bin_edges = np.histogram(phase_difference, bins=num_bins, density=True)\n",
    "    peak_height = np.max(hist)\n",
    "    half_peak_height = peak_height / 2\n",
    "    peak_indices = np.where(hist >= half_peak_height)[0]\n",
    "    fwhm = bin_edges[peak_indices[-1]] - bin_edges[peak_indices[0]]\n",
    "\n",
    "    mean_phase_difference = np.mean(phase_difference)\n",
    "\n",
    "    \n",
    "    save_path = os.path.join(base_dir, genotype, animal, \"Coherence\", anesthesia_level, 'histogram')\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "   \n",
    "    file_name = f\"{band_name} - Channels {map_removido[data1_idx]} and {map_removido[data2_idx]}_last5min.png\"\n",
    "    file_path = os.path.join(save_path, file_name)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(phase_difference, bins=num_bins, color='gray', edgecolor='black', alpha=0.7, density=True)\n",
    "    plt.title(f'Phase Difference Histogram ({band_name} , Channels {map_removido[data1_idx]} vs {map_removido[data2_idx]})')\n",
    "    plt.xlabel('Phase Difference (radians)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid(True)\n",
    "    plt.xticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$', r'$-\\pi/2$', r'0', r'$\\pi/2$', r'$\\pi$'])\n",
    "    \n",
    "    plt.savefig(file_path)\n",
    "    plt.close()\n",
    "    return fwhm, mean_phase_difference\n",
    "\n",
    "freq_bands = {\n",
    "    'delta': (1, 4),\n",
    "    'theta': (4, 12),\n",
    "    'beta': (12, 20),\n",
    "    'low gamma': (20, 40)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# genComb_same_shank = {tuple(sorted(pair)) for pair in [(2,7), (12,18), (23,29), (34,39), (44,50), (55,62)]}\n",
    "# genComb_same_probe = {tuple(sorted(pair)) for pair in [(2,12), (2,18), (2,23), (2,29), (7,12), (7,18), (7,23), \n",
    "#                                                        (7,29), (12,23), (12,29), (18,23), (18,29), (34,44), (34,50), \n",
    "#                                                        (34,55), (34,62), (39,44), (39,50), (39,55), (39,62), \n",
    "#                                                        (44,55), (44,62), (50,55), (50,62)]}\n",
    "genComb_same_shank_hip = {tuple(sorted((channels_for_phase_analysis[i], channels_for_phase_analysis[j])))\n",
    "                          for i, j in [(0, 1), (2, 3), (4, 5)]}\n",
    "\n",
    "genComb_same_shank_pfc = {tuple(sorted((channels_for_phase_analysis[i], channels_for_phase_analysis[j])))\n",
    "                        for i, j in [(6, 7), (8, 9), (10, 11)]}\n",
    "\n",
    "genComb_same_probe_hip = {tuple(sorted((channels_for_phase_analysis[i], channels_for_phase_analysis[j])))\n",
    "                        for i, j in [(0, 2), (0, 3), (0, 4), (0, 5), \n",
    "                                    (1, 2), (1, 3), (1, 4), (1, 5), \n",
    "                                    (2, 4), (2, 5), (3, 4), (3, 5)]}\n",
    "\n",
    "genComb_same_probe_pfc = {tuple(sorted((channels_for_phase_analysis[i], channels_for_phase_analysis[j])))\n",
    "                        for i, j in [(6, 8), (6, 9), (6, 10), (6, 11), \n",
    "                                    (7, 8), (7, 9), (7, 10), (7, 11), \n",
    "                                    (8, 10), (8, 11), (9, 10), (9, 11)]}\n",
    "\n",
    "genComb = list(combinations(channels_for_phase_analysis, 2))\n",
    "\n",
    "save_path = os.path.join(base_dir, genotype, animal, \"Coherence\", anesthesia_level, 'histogram')\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# fwhm_data = []\n",
    "# results_file_path = os.path.join(save_path, 'fwhm_and_mean_results.txt')\n",
    "# if os.path.exists(results_file_path):\n",
    "#     os.remove(results_file_path)\n",
    "# with open(results_file_path, 'w') as f:\n",
    "#     f.write(\"Band, Channel 1, Channel 2, FWHM, Mean Phase Difference\\n\")\n",
    "\n",
    "\n",
    "for band_name, freq_band in freq_bands.items():\n",
    "    fwhm_data = []\n",
    "    # with open(results_file_path, 'a') as f:\n",
    "        \n",
    "    for ch1, ch2 in genComb:\n",
    "        fwhm, mean_phase_difference = phase_consistency_histogram(data_filter, ch1, ch2, SFs, freq_band, band_name, num_bins=100)\n",
    "        sorted_pair = tuple((ch1, ch2))\n",
    "\n",
    "        \n",
    "\n",
    "        if sorted_pair in genComb_same_shank_hip:\n",
    "            colour=\"blue\"\n",
    "        elif sorted_pair in genComb_same_shank_pfc:\n",
    "            colour=\"lightsteelblue\"\n",
    "        elif sorted_pair in  genComb_same_probe_hip:\n",
    "            colour=\"green\"\n",
    "        elif sorted_pair in  genComb_same_probe_pfc:\n",
    "            colour=\"lightgreen\"    \n",
    "        else:\n",
    "            colour=\"red\"\n",
    "\n",
    "        # fwhm_data.append((colour, fwhm, f\"{map_removido[ch1]}-{map_removido[ch2]}\"))\n",
    "        fwhm_data.append([colour, band_name, map_removido[ch1], map_removido[ch2], fwhm, mean_phase_difference])\n",
    "\n",
    "        # f.write(f\"{band_name}, {map_removido[ch1]}, {map_removido[ch2]}, {fwhm:.4f}, {mean_phase_difference:.4f}\\n\")\n",
    "    \n",
    "\n",
    "    color_order = {'blue':0,\"lightsteelblue\":1, 'red':2, 'green':3,\"lightgreen\": 4}\n",
    "\n",
    "    fwhm_data.sort(key=lambda x: color_order[x[0]])\n",
    "\n",
    "    sorted_colours, sorted_bands, sorted_channels1, sorted_channels2, sorted_fwhm, sorted_mean_diff = zip(*fwhm_data)\n",
    "\n",
    "    legend_patches=[Patch(color='blue',label = 'Same shank HIP'),Patch(color='lightsteelblue',label = 'Same shank PFC'),Patch(color='red',label = 'Different Probe'),Patch(color='green',label = 'Different Shanks in HIP'),Patch(color='lightgreen',label = 'Different Shanks in PFC')]\n",
    "    \n",
    "    fwhm_data_no_color = [[entry[1], entry[2], entry[3], entry[4], entry[5]] for entry in fwhm_data]\n",
    "\n",
    "\n",
    "    df_fwhm = pd.DataFrame(fwhm_data_no_color, columns=[\"Band\", \"Channel 1\", \"Channel 2\", \"FWHM\", \"Mean Phase Difference\"])\n",
    "    excel_file_path = os.path.join(save_path, 'fwhm_and_mean_results.xlsx')\n",
    "    df_fwhm.to_excel(excel_file_path, index=False)\n",
    "    \n",
    "    # channel_pairs_labels = []\n",
    "    # for ch1, ch2 in zip(sorted_channels1, sorted_channels2):\n",
    "    #     channel_label = f\"{map_removido[ch1]}-{map_removido[ch2]}\"\n",
    "    #     channel_pairs_labels.append(channel_label)\n",
    "\n",
    "    plt.figure(figsize=(26, 6))\n",
    "    bars = plt.bar(range(len(sorted_channels1)), sorted_fwhm, color=sorted_colours)\n",
    "    # plt.bar(sorted_channels1, sorted_fwhm, color=sorted_colours)\n",
    "    plt.title(f\"FWHM (Full Width at Half Maximum) for Phase Difference - {band_name}\")\n",
    "    plt.xlabel(\"Channel Pairs\")\n",
    "    plt.ylabel(\"FWHM\")\n",
    "    channel_pairs_labels = [f\"{ch1}-{ch2}\" for ch1, ch2 in zip(sorted_channels1, sorted_channels2)]\n",
    "    plt.xticks(range(len(sorted_channels1)), channel_pairs_labels, rotation=45)\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.grid()\n",
    "    plt.legend(handles=legend_patches, loc='upper right')\n",
    "    plt.ylim(0,7)\n",
    "    plt.yticks(np.arange(0, 7, 1)) \n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = os.path.join(base_dir, genotype, animal, \"Coherence\", anesthesia_level, 'histogram')\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "# plt.savefig(fwhm_plot_path)\n",
    "# plt.close()\n",
    "    plt.savefig(os.path.join(save_path, f\"FWHM_{band_name}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_channels1: (24, 22, 14, 56, 54, 46, 24, 24, 24, 24, 24, 24, 31, 31, 31, 31, 31, 31, 22, 22, 22, 22, 22, 22, 27, 27, 27, 27, 27, 27, 14, 14, 14, 14, 14, 14, 0, 0, 0, 0, 0, 0, 24, 24, 24, 24, 31, 31, 31, 31, 22, 22, 27, 27, 56, 56, 56, 56, 63, 63, 63, 63, 54, 54, 59, 59)\n",
      "sorted_channels2: (31, 27, 0, 63, 59, 32, 56, 63, 54, 59, 46, 32, 56, 63, 54, 59, 46, 32, 56, 63, 54, 59, 46, 32, 56, 63, 54, 59, 46, 32, 56, 63, 54, 59, 46, 32, 56, 63, 54, 59, 46, 32, 22, 27, 14, 0, 22, 27, 14, 0, 14, 0, 14, 0, 54, 59, 46, 32, 54, 59, 46, 32, 46, 32, 46, 32)\n",
      "[19, 18, 24, 17, 23, 16, 21, 31, 20, 30, 25, 7, 22, 12, 29, 11, 28, 10, 27, 8, 26, 2, 3, 14, 6, 13, 9, 1, 5, 0, 4, 15, 51, 50, 56, 49, 55, 53, 63, 52, 62, 57, 39, 54, 44, 61, 43, 60, 42, 59, 40, 58, 34, 35, 46, 38, 45, 41, 33, 37, 32, 36]\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted_channels1:\", sorted_channels1)\n",
    "print(\"sorted_channels2:\", sorted_channels2)\n",
    "print(map_removido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180000, 62)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magnitude Coherence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase Coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase Coherence per band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase Lag Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pli(channel_1, channel_2, sfreq, nperseg, noverlap):\n",
    "    f, Pxy = signal.csd(channel_1, channel_2, fs=sfreq, nperseg=nperseg, noverlap=noverlap)\n",
    "    phase_diff = np.angle(Pxy)\n",
    "    pli = np.abs(np.mean(np.sign(phase_diff)))\n",
    "    return pli, phase_diff\n",
    "\n",
    "# path_map = {\n",
    "#     ('KO', 'B0'): os.path.join(base_dir, \"KO_B0\", \"Coherence\"),\n",
    "#     ('KO', 'B1'): os.path.join(base_dir, \"KO_B1\", \"Coherence\"),\n",
    "#     ('WT', 'A0'): os.path.join(base_dir, \"WT_A0\", \"Coherence\"),\n",
    "#     ('WT', 'A1'): os.path.join(base_dir, \"WT_A1\", \"Coherence\")\n",
    "# }\n",
    "# save_path = path_map.get((genotype, animal), base_dir)\n",
    "# txt_file = os.path.join(save_path, f\"{genotype} {anesthesia_level}_PLI_last5min.txt\")\n",
    "# NPS = 1200\n",
    "# NVL = NPS // 2\n",
    "\n",
    "# freq_bands = {\n",
    "#     'delta': (1, 4),\n",
    "#     'theta': (4, 12),\n",
    "#     'beta': (12, 20),\n",
    "#     'low gamma': (20, 40)\n",
    "# }\n",
    "\n",
    "# with open(txt_file, 'w') as f:\n",
    "#     f.write(\"Channel 1\\tChannel 2\\tBand\\tPLI\\n\")\n",
    "    \n",
    "#     channels_for_coherence = [2, 7, 12, 18, 23, 29, 34, 40]\n",
    "    \n",
    "#     for channel_1_idx, channel_2_idx in combinations(channels_for_coherence, 2):\n",
    "#         channel_1 = data_filter[:, channel_1_idx]\n",
    "#         channel_2 = data_filter[:, channel_2_idx]\n",
    "        \n",
    "#         for band_name, (lowcut, highcut) in freq_bands.items():\n",
    "#             print('low', lowcut)\n",
    "#             print('high',highcut)\n",
    "#             filtered_channel_1 = butter_bandpass_filter(channel_1, lowcut, highcut, SFs, order=5)\n",
    "#             filtered_channel_2 = butter_bandpass_filter(channel_2, lowcut, highcut, SFs, order=5)\n",
    "            \n",
    "            \n",
    "#             pli, phase_diff = calculate_pli(filtered_channel_1, filtered_channel_2, SFs, NPS, NVL)\n",
    "            \n",
    "            \n",
    "#             f.write(f\"{map[channel_1_idx]}\\t{map[channel_2_idx]}\\t{band_name}\\t{pli:.4f}\\n\")\n",
    "            \n",
    "#             print(f\"Band: {band_name}, Channels: {map[channel_1_idx]}-{map[channel_2_idx]}, PLI: {pli:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from itertools import combinations\n",
    "\n",
    "# Função para calcular a coerência de fase\n",
    "def phase_coherence(Pxx, Pyy, Pxy):\n",
    "    c=np.angle(Pxy)\n",
    "    return np.cos(c)\n",
    "\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def plot_phase_coherence(data, SFs, NPS, NVL, freq_bands, channels_for_phase_analysis):\n",
    "    for data1_idx, data2_idx in combinations(channels_for_phase_analysis, 2):\n",
    "        # Extrair os dados dos canais específicos\n",
    "        data1 = data[:, data1_idx]\n",
    "        data2 = data[:, data2_idx]\n",
    "\n",
    "        for band_name, (lowcut, highcut) in freq_bands.items():\n",
    "            # Aplicar filtro passa-banda para isolar a banda\n",
    "            filtered_data1 = bandpass_filter(data1, lowcut, highcut, SFs)\n",
    "            filtered_data2 = bandpass_filter(data2, lowcut, highcut, SFs)\n",
    "\n",
    "            # Calcular as densidades espectrais de potência (Pxx, Pyy) e densidade espectral cruzada (Pxy)\n",
    "            f, Pxx = signal.welch(filtered_data1, fs=SFs, nperseg=NPS, noverlap=NVL)\n",
    "            _, Pyy = signal.welch(filtered_data2, fs=SFs, nperseg=NPS, noverlap=NVL)\n",
    "            _, Pxy = signal.csd(filtered_data1, filtered_data2, fs=SFs, nperseg=NPS, noverlap=NVL)\n",
    "\n",
    "            # Filtrar as frequências para a banda desejada\n",
    "            freq_indices = np.where((f >= lowcut) & (f <= highcut))[0]\n",
    "\n",
    "            # Coerência de fase normalizada\n",
    "            C_f = phase_coherence(Pxx[freq_indices], Pyy[freq_indices], Pxy[freq_indices])\n",
    "\n",
    "            # Gráfico linear de coerência de fase\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.plot(f[freq_indices], np.abs(C_f), label=f'{band_name} ({lowcut}-{highcut} Hz)')\n",
    "            plt.title(f\"Coerência de Fase Linear (Canais {data1_idx} e {data2_idx})\")\n",
    "            plt.xlabel(\"Frequência (Hz)\")\n",
    "            plt.ylabel(\"Coerência de Fase (0-1)\")\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "\n",
    "            # Gráfico polar da distribuição de fases\n",
    "            phases = np.angle(Pxy[freq_indices])\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            ax = plt.subplot(111, polar=True)\n",
    "            ax.hist(phases, bins=50, density=True, alpha=0.7)\n",
    "            ax.set_title(f\"Distribuição das Fases (Polar)\\n{band_name} ({lowcut}-{highcut} Hz)\\nCanais {data1_idx} e {data2_idx}\")\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# duration = 5 * 60  # em segundos\n",
    "# N = int(SFs * duration)  # número total de pontos\n",
    "# # Tempo\n",
    "# w=2*np.pi*30\n",
    "# t = np.linspace(0, duration, N, endpoint=False)\n",
    "# s_4=2*np.pi*np.cos(2*w*t-np.pi)\n",
    "# s_6=2*np.pi*np.cos(2*w*t)\n",
    "\n",
    "\n",
    "# data_filter_list_test2 = np.column_stack((s_4,s_6))\n",
    "\n",
    "freq_bands = {\n",
    "    'Delta': (1, 4),\n",
    "    'Theta': (4, 12),\n",
    "    'Beta': (12, 20),\n",
    "    'Low Gamma': (20, 40)\n",
    "} \n",
    "# channels_for_phase_analysis = [2, 7, 12, 18, 23, 29, 34, 40]  # Canais que você quer analisar\n",
    "# channels_for_phase_analysis = [2, 7]\n",
    "# plot_phase_coherence(data_filter, SFs, NPS, NVL, freq_bands, channels_for_phase_analysis)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import hilbert, butter, filtfilt\n",
    "from itertools import combinations\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def hilbert_phase_coherence(data1, data2, fs, lowcut, highcut):\n",
    "    # Aplicar filtro passa-banda\n",
    "    filtered_data1 = bandpass_filter(data1, lowcut, highcut, fs)\n",
    "    filtered_data2 = bandpass_filter(data2, lowcut, highcut, fs)\n",
    "    \n",
    "    # Obter o sinal analítico com Hilbert\n",
    "    analytic_signal1 = hilbert(filtered_data1)\n",
    "    analytic_signal2 = hilbert(filtered_data2)\n",
    "    \n",
    "    # Calcular as fases instantâneas\n",
    "    phase1 = np.angle(analytic_signal1)\n",
    "    phase2 = np.angle(analytic_signal2)\n",
    "    \n",
    "    # Calcular a diferença de fases instantâneas\n",
    "    phase_diff = phase1 - phase2\n",
    "    \n",
    "    # Calcular a coerência de fase\n",
    "    coherence = np.abs(np.mean(np.exp(1j * phase_diff)))\n",
    "    return coherence, phase_diff\n",
    "\n",
    "def plot_hilbert_phase_coherence(data, fs, freq_bands, channels_for_phase_analysis):\n",
    "    for data1_idx, data2_idx in combinations(channels_for_phase_analysis, 2):\n",
    "        # Extrair os dados dos canais específicos\n",
    "        data1 = data[:, data1_idx]\n",
    "        data2 = data[:, data2_idx]\n",
    "        \n",
    "        for band_name, (lowcut, highcut) in freq_bands.items():\n",
    "            \n",
    "            coherence, phase_diff = hilbert_phase_coherence(data1, data2, fs, lowcut, highcut)\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            time = np.arange(len(data1)) / fs  # Tempo\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plt.plot(time[:10000], phase_diff[:10000], label=f'Fase Canal {data1_idx}')\n",
    "            plt.title(f'Fase Instantânea ao Longo do Tempo\\n{band_name} ({lowcut}-{highcut} Hz)')\n",
    "            plt.xlabel('Tempo (s)')\n",
    "            plt.ylabel('Fase (radianos)')\n",
    "            plt.legend(loc='upper right')\n",
    "\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            ax = plt.subplot(111, polar=True) \n",
    "            # ax.scatter(phase_diff, np.ones_like(phase_diff), alpha=0.7, color='b')\n",
    "            ax.hist(phase_diff, bins=80, density=True, alpha=0.7, color='b', rwidth=0.5)\n",
    "            ax.set_title(f\"Distribuição das Fases (Polar)\\n{band_name} ({lowcut}-{highcut} Hz)\\nCanais {data1_idx} e {data2_idx}\")\n",
    "            ax.set_theta_zero_location(\"N\")  # Zero no topo\n",
    "            ax.set_theta_direction(-1)  \n",
    "            plt.show()\n",
    "            \n",
    "            # Exibir o valor da coerência de fase\n",
    "            print(f\"Coerência de Fase (Hilbert) - {band_name} ({lowcut}-{highcut} Hz): {coherence:.3f}\")\n",
    "\n",
    "freq_bands = {\n",
    "    'Delta': (1, 4),\n",
    "    'Theta': (4, 12),\n",
    "    'Beta': (12, 20),\n",
    "    'Low Gamma': (20, 40)\n",
    "}\n",
    "# channels_for_phase_analysis = [2,34]\n",
    "# channels_for_phase_analysis = [2, 7, 12, 18, 23, 29, 34, 40]\n",
    "# plot_hilbert_phase_coherence(data_filter, SFs, freq_bands, channels_for_phase_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Astrogang Ephys_Patricia\\PLOTS\\Set 115 - FOXO1-\\WT\\B1\\Spectrogram\\2\n"
     ]
    }
   ],
   "source": [
    "animal_path = os.path.join(base_dir, genotype, animal)\n",
    "spec_path = os.path.join(animal_path, \"Spectrogram\")\n",
    "save_path = os.path.join(spec_path,anesthesia_level)\n",
    "print(save_path)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "def spectrogram(data):\n",
    "    for i in range(data.shape[1]):\n",
    "        f, t, Sxx = signal.spectrogram(data[:,i]*0.195,fs=SFs, window='hann', nperseg=NPS, noverlap=NVL,scaling='density')\n",
    "        plt.figure()\n",
    "        pcm = plt.pcolormesh(t, f, Sxx, shading='gouraud')\n",
    "        plt.ylabel('Frequency [Hz]')\n",
    "        plt.xlabel('Time [sec]')\n",
    "        plt.title(rf'Spectrogram Channel {map[i]}')\n",
    "        plt.ylim([0,100])\n",
    "        cbar = plt.colorbar(pcm)\n",
    "        cbar.set_label(' power Density [V$^2$/Hz]')\n",
    "        # print(map[i])\n",
    "        plt.tight_layout()\n",
    "        file_name = f\"{genotype}_CH {map_removido[i]}.png\"\n",
    "        # file_name = f\"{genotype}_{anesthesia_level}_PSD_by_allshank_last5.png\"\n",
    "        file_path = os.path.join(save_path, file_name)\n",
    "        plt.savefig(file_path)\n",
    "        plt.close()\n",
    "\n",
    "spectrogram(data_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pactools import Comodulogram\n",
    "# from pactools.dar_model import DAR, extract_driver\n",
    "# from itertools import combinations\n",
    "\n",
    "### map_removido = np.delete(map, np.where(np.isin(map, [47, 48])))\n",
    "\n",
    "# animal_path = os.path.join(base_dir, genotype, animal)\n",
    "# pac_path = os.path.join(animal_path,\"PAC\",anesthesia_level,'ATE_300')\n",
    "# os.makedirs(pac_path, exist_ok=True)\n",
    "\n",
    "# low_fq_range=np.linspace(1,20,50)\n",
    "# # low_fq_range=np.linspace(1,4,25)\n",
    "# high_fq_range = np.linspace(20, 100, 200)\n",
    "# low_fq_width=1\n",
    "# \n",
    "# for ch1, ch2 in combinations(channels_for_phase_analysis, 2):\n",
    "# # já a contar com os canais removidos(47 e 48)\n",
    "#     ch_low=data_filter[:,ch1]\n",
    "#     ch_high=data_filter[:,ch2]\n",
    "\n",
    "# # dar=DAR(ordar=20,ordriv=2,criterion='bic')\n",
    "# # low_fq = 8 \n",
    "# # sigdriv, sigin, sigdriv_imag = extract_driver(\n",
    "# #     sigs=ch_low,  \n",
    "# #     fs=SFs, \n",
    "# #     low_fq=low_fq, \n",
    "# #     bandwidth=low_fq_width,\n",
    "# #     extract_complex=True, \n",
    "# #     random_state=0, \n",
    "# #     fill=2\n",
    "# # )\n",
    "\n",
    "# # Fit the DAR model with the extracted signals\n",
    "# # dar.fit(sigin=sigin, sigdriv=sigdriv, sigdriv_imag=sigdriv_imag, fs=SFs)\n",
    "# ## ordar - order of the autoregressive model ( how many past values are used)\n",
    "# ## ordriv - order of the driver signal (how many past driver values are considered)\n",
    "# ## AR model: the currrent value depends on p previous values; DAR: prediction also depends on an external 'DRIVER' signal (can be from \n",
    "# ## another time series or a specific frequency component)\n",
    "\n",
    "#     method='duprelatour'\n",
    "#     # method=dar\n",
    "#     n_surrogates=50\n",
    "#     n_jobs=1\n",
    "\n",
    "#     # ch_low = butter_bandpass_filter(data_filter[:, ch1], 4, 12, SFs,order=5)\n",
    "#     # ch_high = butter_bandpass_filter(data_filter[:, ch2], 20, 40, SFs,order=5)\n",
    "\n",
    "#     fig1=plt.figure(figsize=(25,10))\n",
    "\n",
    "#     z_score=4\n",
    "#     p_value=0.05\n",
    "\n",
    "#     comod_hip_pfc= Comodulogram(fs=SFs, low_fq_range=low_fq_range,\n",
    "#                                 low_fq_width=low_fq_width,method=method,progress_bar=True)\n",
    "\n",
    "#     comod_hip_pfc.fit(ch_low,ch_high)\n",
    "#     comod_hip_pfc.plot(titles=[f'Low: Ch {map_removido[ch1]} (Phase) -> High: Ch {map_removido[ch2]} (Amplitude)'])\n",
    "#     plt.tight_layout()\n",
    "#     file_name = f\"ph_hip_amp_pfc_{map_removido[ch1]}_{map_removido[ch2]}_{method}.png\"\n",
    "#     file_path = os.path.join(pac_path, file_name)\n",
    "#     plt.savefig(file_path,bbox_inches='tight') \n",
    "#     plt.close() \n",
    "\n",
    "#     fig2=plt.figure(figsize=(25,10))\n",
    "\n",
    "#     comod_pfc_hip= Comodulogram(fs=SFs, low_fq_range=low_fq_range,\n",
    "#                                 low_fq_width=low_fq_width,method=method,progress_bar=True)\n",
    "#     comod_hip_pfc.fit(ch_high, ch_low)\n",
    "#     #contour_method='comod_max',contour_level=p_value, ,high_fq_range=high_fq_range n_surrogates=n_surrogates,\n",
    "#     comod_hip_pfc.plot(titles=[f'Low: Ch {map_removido[ch2]} (Phase) -> High: Ch {map_removido[ch1]} (Amplitude)'])\n",
    "#     plt.tight_layout()\n",
    "#     file_name = f\"ph_pfc_amp_hip_{map_removido[ch1]}_{map_removido[ch2]}_{method}.png\"\n",
    "#     file_path = os.path.join(pac_path, file_name)\n",
    "#     plt.savefig(file_path,bbox_inches='tight')\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPS 1200\n",
      "NVL 600\n"
     ]
    }
   ],
   "source": [
    "print('NPS',NPS)\n",
    "print('NVL',NVL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
